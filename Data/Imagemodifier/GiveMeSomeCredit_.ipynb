{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "name": "",
  "signature": "sha256:50213b9854d0cfbf97052b47c7ac0c3df2896f161de3b737a3bc96234bd37474"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "\n",
      "## Introduction au Machine Learning \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dans ce notebook, on illustre l'int\u00e9r\u00eat des for\u00eats al\u00e9atoires et du boosting en utilisant les donn\u00e9es du challenge Kaggle intitul\u00e9 `Give Me Some Credit`"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "0. Pr\u00e9liminaires"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%matplotlib inline\n",
      "from sklearn import neighbors, datasets\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Chargement des donn\u00e9es"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Il existe plusieurs mani\u00e8res de charger un fichier csv en m\u00e9moire avec Python. Ici on utilisera directement une des plus puissantes pour arriver \u00e0 un r\u00e9sultat qui soit tr\u00e8s proche de ce qu'on \u00e9crit en R : on utilise la librairie [pandas](http://pandas.pydata.org)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "datapath = \"../givemesomecredit/\"\n",
      "trainf = \"cs-training.csv\"\n",
      "testf = \"cs-test.csv\"\n",
      "dataf = datapath + trainf\n",
      "testf = datapath + testf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'../givemesomecredit/cs-training.csv'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pd.read_csv(dataf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>SeriousDlqin2yrs</th>\n",
        "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
        "      <th>age</th>\n",
        "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
        "      <th>DebtRatio</th>\n",
        "      <th>MonthlyIncome</th>\n",
        "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
        "      <th>NumberOfTimes90DaysLate</th>\n",
        "      <th>NumberRealEstateLoansOrLines</th>\n",
        "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
        "      <th>NumberOfDependents</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0.766127</td>\n",
        "      <td>45</td>\n",
        "      <td>2</td>\n",
        "      <td>0.802982</td>\n",
        "      <td>9120.0</td>\n",
        "      <td>13</td>\n",
        "      <td>0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.957151</td>\n",
        "      <td>40</td>\n",
        "      <td>0</td>\n",
        "      <td>0.121876</td>\n",
        "      <td>2600.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0.658180</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>0.085113</td>\n",
        "      <td>3042.0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0.233810</td>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.036050</td>\n",
        "      <td>3300.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0.907239</td>\n",
        "      <td>49</td>\n",
        "      <td>1</td>\n",
        "      <td>0.024926</td>\n",
        "      <td>63588.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0.213179</td>\n",
        "      <td>74</td>\n",
        "      <td>0</td>\n",
        "      <td>0.375607</td>\n",
        "      <td>3500.0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0.305682</td>\n",
        "      <td>57</td>\n",
        "      <td>0</td>\n",
        "      <td>5710.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0.754464</td>\n",
        "      <td>39</td>\n",
        "      <td>0</td>\n",
        "      <td>0.209940</td>\n",
        "      <td>3500.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>9</td>\n",
        "      <td>0</td>\n",
        "      <td>0.116951</td>\n",
        "      <td>27</td>\n",
        "      <td>0</td>\n",
        "      <td>46.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>0.189169</td>\n",
        "      <td>57</td>\n",
        "      <td>0</td>\n",
        "      <td>0.606291</td>\n",
        "      <td>23684.0</td>\n",
        "      <td>9</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>11</td>\n",
        "      <td>0</td>\n",
        "      <td>0.644226</td>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.309476</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>12</td>\n",
        "      <td>0</td>\n",
        "      <td>0.018798</td>\n",
        "      <td>51</td>\n",
        "      <td>0</td>\n",
        "      <td>0.531529</td>\n",
        "      <td>6501.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>13</td>\n",
        "      <td>0</td>\n",
        "      <td>0.010352</td>\n",
        "      <td>46</td>\n",
        "      <td>0</td>\n",
        "      <td>0.298354</td>\n",
        "      <td>12454.0</td>\n",
        "      <td>13</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>14</td>\n",
        "      <td>1</td>\n",
        "      <td>0.964673</td>\n",
        "      <td>40</td>\n",
        "      <td>3</td>\n",
        "      <td>0.382965</td>\n",
        "      <td>13700.0</td>\n",
        "      <td>9</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>15</td>\n",
        "      <td>0</td>\n",
        "      <td>0.019657</td>\n",
        "      <td>76</td>\n",
        "      <td>0</td>\n",
        "      <td>477.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>16</td>\n",
        "      <td>0</td>\n",
        "      <td>0.548458</td>\n",
        "      <td>64</td>\n",
        "      <td>0</td>\n",
        "      <td>0.209892</td>\n",
        "      <td>11362.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>17</td>\n",
        "      <td>0</td>\n",
        "      <td>0.061086</td>\n",
        "      <td>78</td>\n",
        "      <td>0</td>\n",
        "      <td>2058.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>18</td>\n",
        "      <td>0</td>\n",
        "      <td>0.166284</td>\n",
        "      <td>53</td>\n",
        "      <td>0</td>\n",
        "      <td>0.188274</td>\n",
        "      <td>8800.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>19</td>\n",
        "      <td>0</td>\n",
        "      <td>0.221813</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.527888</td>\n",
        "      <td>3280.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>20</td>\n",
        "      <td>0</td>\n",
        "      <td>0.602794</td>\n",
        "      <td>25</td>\n",
        "      <td>0</td>\n",
        "      <td>0.065868</td>\n",
        "      <td>333.0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>21</td>\n",
        "      <td>0</td>\n",
        "      <td>0.200923</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.430046</td>\n",
        "      <td>12300.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>22</td>\n",
        "      <td>1</td>\n",
        "      <td>0.025656</td>\n",
        "      <td>38</td>\n",
        "      <td>0</td>\n",
        "      <td>0.475841</td>\n",
        "      <td>3000.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>23</td>\n",
        "      <td>0</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>39</td>\n",
        "      <td>0</td>\n",
        "      <td>0.241104</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>24</td>\n",
        "      <td>0</td>\n",
        "      <td>0.075427</td>\n",
        "      <td>32</td>\n",
        "      <td>0</td>\n",
        "      <td>0.085512</td>\n",
        "      <td>7916.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>25</td>\n",
        "      <td>0</td>\n",
        "      <td>0.046560</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>0.241622</td>\n",
        "      <td>2416.0</td>\n",
        "      <td>9</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>26</td>\n",
        "      <td>1</td>\n",
        "      <td>0.392248</td>\n",
        "      <td>50</td>\n",
        "      <td>0</td>\n",
        "      <td>1.595253</td>\n",
        "      <td>4676.0</td>\n",
        "      <td>14</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>27</td>\n",
        "      <td>0</td>\n",
        "      <td>0.052436</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>0.097672</td>\n",
        "      <td>8333.0</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>28</td>\n",
        "      <td>0</td>\n",
        "      <td>0.034421</td>\n",
        "      <td>69</td>\n",
        "      <td>0</td>\n",
        "      <td>0.042383</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>17</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>29</td>\n",
        "      <td>0</td>\n",
        "      <td>0.452516</td>\n",
        "      <td>24</td>\n",
        "      <td>0</td>\n",
        "      <td>0.011761</td>\n",
        "      <td>3400.0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.392995</td>\n",
        "      <td>58</td>\n",
        "      <td>2</td>\n",
        "      <td>0.436103</td>\n",
        "      <td>5500.0</td>\n",
        "      <td>15</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149970</th>\n",
        "      <td>149971</td>\n",
        "      <td>0</td>\n",
        "      <td>0.025449</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>0.253855</td>\n",
        "      <td>15500.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149971</th>\n",
        "      <td>149972</td>\n",
        "      <td>0</td>\n",
        "      <td>0.058001</td>\n",
        "      <td>83</td>\n",
        "      <td>0</td>\n",
        "      <td>0.013997</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149972</th>\n",
        "      <td>149973</td>\n",
        "      <td>0</td>\n",
        "      <td>0.071273</td>\n",
        "      <td>42</td>\n",
        "      <td>0</td>\n",
        "      <td>0.008638</td>\n",
        "      <td>6945.0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149973</th>\n",
        "      <td>149974</td>\n",
        "      <td>0</td>\n",
        "      <td>1.026395</td>\n",
        "      <td>44</td>\n",
        "      <td>0</td>\n",
        "      <td>0.494819</td>\n",
        "      <td>5500.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149974</th>\n",
        "      <td>149975</td>\n",
        "      <td>0</td>\n",
        "      <td>0.962721</td>\n",
        "      <td>61</td>\n",
        "      <td>2</td>\n",
        "      <td>0.603479</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>11</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149975</th>\n",
        "      <td>149976</td>\n",
        "      <td>0</td>\n",
        "      <td>0.022088</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>2716.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149976</th>\n",
        "      <td>149977</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000627</td>\n",
        "      <td>76</td>\n",
        "      <td>0</td>\n",
        "      <td>60.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149977</th>\n",
        "      <td>149978</td>\n",
        "      <td>0</td>\n",
        "      <td>0.236450</td>\n",
        "      <td>29</td>\n",
        "      <td>0</td>\n",
        "      <td>349.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149978</th>\n",
        "      <td>149979</td>\n",
        "      <td>0</td>\n",
        "      <td>0.917635</td>\n",
        "      <td>52</td>\n",
        "      <td>2</td>\n",
        "      <td>0.259496</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149979</th>\n",
        "      <td>149980</td>\n",
        "      <td>1</td>\n",
        "      <td>0.224711</td>\n",
        "      <td>55</td>\n",
        "      <td>0</td>\n",
        "      <td>0.057235</td>\n",
        "      <td>8700.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149980</th>\n",
        "      <td>149981</td>\n",
        "      <td>0</td>\n",
        "      <td>0.067644</td>\n",
        "      <td>64</td>\n",
        "      <td>0</td>\n",
        "      <td>0.254976</td>\n",
        "      <td>5525.0</td>\n",
        "      <td>12</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149981</th>\n",
        "      <td>149982</td>\n",
        "      <td>0</td>\n",
        "      <td>0.810012</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.121752</td>\n",
        "      <td>6849.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>4.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149982</th>\n",
        "      <td>149983</td>\n",
        "      <td>0</td>\n",
        "      <td>0.021046</td>\n",
        "      <td>37</td>\n",
        "      <td>0</td>\n",
        "      <td>0.250272</td>\n",
        "      <td>2760.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149983</th>\n",
        "      <td>149984</td>\n",
        "      <td>0</td>\n",
        "      <td>0.002485</td>\n",
        "      <td>82</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000800</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149984</th>\n",
        "      <td>149985</td>\n",
        "      <td>0</td>\n",
        "      <td>0.037548</td>\n",
        "      <td>84</td>\n",
        "      <td>0</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149985</th>\n",
        "      <td>149986</td>\n",
        "      <td>0</td>\n",
        "      <td>0.954409</td>\n",
        "      <td>26</td>\n",
        "      <td>0</td>\n",
        "      <td>0.324962</td>\n",
        "      <td>1950.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149986</th>\n",
        "      <td>149987</td>\n",
        "      <td>0</td>\n",
        "      <td>0.168102</td>\n",
        "      <td>49</td>\n",
        "      <td>0</td>\n",
        "      <td>0.080384</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>16</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149987</th>\n",
        "      <td>149988</td>\n",
        "      <td>0</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>28</td>\n",
        "      <td>0</td>\n",
        "      <td>0.055692</td>\n",
        "      <td>3249.0</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149988</th>\n",
        "      <td>149989</td>\n",
        "      <td>0</td>\n",
        "      <td>0.902051</td>\n",
        "      <td>31</td>\n",
        "      <td>1</td>\n",
        "      <td>0.347924</td>\n",
        "      <td>7515.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149989</th>\n",
        "      <td>149990</td>\n",
        "      <td>0</td>\n",
        "      <td>0.013356</td>\n",
        "      <td>62</td>\n",
        "      <td>0</td>\n",
        "      <td>0.001408</td>\n",
        "      <td>9233.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149990</th>\n",
        "      <td>149991</td>\n",
        "      <td>0</td>\n",
        "      <td>0.055518</td>\n",
        "      <td>46</td>\n",
        "      <td>0</td>\n",
        "      <td>0.609779</td>\n",
        "      <td>4335.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149991</th>\n",
        "      <td>149992</td>\n",
        "      <td>0</td>\n",
        "      <td>0.104112</td>\n",
        "      <td>59</td>\n",
        "      <td>0</td>\n",
        "      <td>0.477658</td>\n",
        "      <td>10316.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149992</th>\n",
        "      <td>149993</td>\n",
        "      <td>0</td>\n",
        "      <td>0.871976</td>\n",
        "      <td>50</td>\n",
        "      <td>0</td>\n",
        "      <td>4132.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>11</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149993</th>\n",
        "      <td>149994</td>\n",
        "      <td>0</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>820.0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149994</th>\n",
        "      <td>149995</td>\n",
        "      <td>0</td>\n",
        "      <td>0.385742</td>\n",
        "      <td>50</td>\n",
        "      <td>0</td>\n",
        "      <td>0.404293</td>\n",
        "      <td>3400.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149995</th>\n",
        "      <td>149996</td>\n",
        "      <td>0</td>\n",
        "      <td>0.040674</td>\n",
        "      <td>74</td>\n",
        "      <td>0</td>\n",
        "      <td>0.225131</td>\n",
        "      <td>2100.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149996</th>\n",
        "      <td>149997</td>\n",
        "      <td>0</td>\n",
        "      <td>0.299745</td>\n",
        "      <td>44</td>\n",
        "      <td>0</td>\n",
        "      <td>0.716562</td>\n",
        "      <td>5584.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149997</th>\n",
        "      <td>149998</td>\n",
        "      <td>0</td>\n",
        "      <td>0.246044</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>3870.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>18</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149998</th>\n",
        "      <td>149999</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>5716.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149999</th>\n",
        "      <td>150000</td>\n",
        "      <td>0</td>\n",
        "      <td>0.850283</td>\n",
        "      <td>64</td>\n",
        "      <td>0</td>\n",
        "      <td>0.249908</td>\n",
        "      <td>8158.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>150000 rows \u00d7 12 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "        Unnamed: 0  SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  \\\n",
        "0                1                 1                              0.766127   \n",
        "1                2                 0                              0.957151   \n",
        "2                3                 0                              0.658180   \n",
        "3                4                 0                              0.233810   \n",
        "4                5                 0                              0.907239   \n",
        "5                6                 0                              0.213179   \n",
        "6                7                 0                              0.305682   \n",
        "7                8                 0                              0.754464   \n",
        "8                9                 0                              0.116951   \n",
        "9               10                 0                              0.189169   \n",
        "10              11                 0                              0.644226   \n",
        "11              12                 0                              0.018798   \n",
        "12              13                 0                              0.010352   \n",
        "13              14                 1                              0.964673   \n",
        "14              15                 0                              0.019657   \n",
        "15              16                 0                              0.548458   \n",
        "16              17                 0                              0.061086   \n",
        "17              18                 0                              0.166284   \n",
        "18              19                 0                              0.221813   \n",
        "19              20                 0                              0.602794   \n",
        "20              21                 0                              0.200923   \n",
        "21              22                 1                              0.025656   \n",
        "22              23                 0                              1.000000   \n",
        "23              24                 0                              0.075427   \n",
        "24              25                 0                              0.046560   \n",
        "25              26                 1                              0.392248   \n",
        "26              27                 0                              0.052436   \n",
        "27              28                 0                              0.034421   \n",
        "28              29                 0                              0.452516   \n",
        "29              30                 0                              0.392995   \n",
        "...            ...               ...                                   ...   \n",
        "149970      149971                 0                              0.025449   \n",
        "149971      149972                 0                              0.058001   \n",
        "149972      149973                 0                              0.071273   \n",
        "149973      149974                 0                              1.026395   \n",
        "149974      149975                 0                              0.962721   \n",
        "149975      149976                 0                              0.022088   \n",
        "149976      149977                 0                              0.000627   \n",
        "149977      149978                 0                              0.236450   \n",
        "149978      149979                 0                              0.917635   \n",
        "149979      149980                 1                              0.224711   \n",
        "149980      149981                 0                              0.067644   \n",
        "149981      149982                 0                              0.810012   \n",
        "149982      149983                 0                              0.021046   \n",
        "149983      149984                 0                              0.002485   \n",
        "149984      149985                 0                              0.037548   \n",
        "149985      149986                 0                              0.954409   \n",
        "149986      149987                 0                              0.168102   \n",
        "149987      149988                 0                              1.000000   \n",
        "149988      149989                 0                              0.902051   \n",
        "149989      149990                 0                              0.013356   \n",
        "149990      149991                 0                              0.055518   \n",
        "149991      149992                 0                              0.104112   \n",
        "149992      149993                 0                              0.871976   \n",
        "149993      149994                 0                              1.000000   \n",
        "149994      149995                 0                              0.385742   \n",
        "149995      149996                 0                              0.040674   \n",
        "149996      149997                 0                              0.299745   \n",
        "149997      149998                 0                              0.246044   \n",
        "149998      149999                 0                              0.000000   \n",
        "149999      150000                 0                              0.850283   \n",
        "\n",
        "        age  NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  MonthlyIncome  \\\n",
        "0        45                                     2     0.802982         9120.0   \n",
        "1        40                                     0     0.121876         2600.0   \n",
        "2        38                                     1     0.085113         3042.0   \n",
        "3        30                                     0     0.036050         3300.0   \n",
        "4        49                                     1     0.024926        63588.0   \n",
        "5        74                                     0     0.375607         3500.0   \n",
        "6        57                                     0  5710.000000            NaN   \n",
        "7        39                                     0     0.209940         3500.0   \n",
        "8        27                                     0    46.000000            NaN   \n",
        "9        57                                     0     0.606291        23684.0   \n",
        "10       30                                     0     0.309476         2500.0   \n",
        "11       51                                     0     0.531529         6501.0   \n",
        "12       46                                     0     0.298354        12454.0   \n",
        "13       40                                     3     0.382965        13700.0   \n",
        "14       76                                     0   477.000000            0.0   \n",
        "15       64                                     0     0.209892        11362.0   \n",
        "16       78                                     0  2058.000000            NaN   \n",
        "17       53                                     0     0.188274         8800.0   \n",
        "18       43                                     0     0.527888         3280.0   \n",
        "19       25                                     0     0.065868          333.0   \n",
        "20       43                                     0     0.430046        12300.0   \n",
        "21       38                                     0     0.475841         3000.0   \n",
        "22       39                                     0     0.241104         2500.0   \n",
        "23       32                                     0     0.085512         7916.0   \n",
        "24       58                                     0     0.241622         2416.0   \n",
        "25       50                                     0     1.595253         4676.0   \n",
        "26       58                                     0     0.097672         8333.0   \n",
        "27       69                                     0     0.042383         2500.0   \n",
        "28       24                                     0     0.011761         3400.0   \n",
        "29       58                                     2     0.436103         5500.0   \n",
        "...     ...                                   ...          ...            ...   \n",
        "149970   58                                     0     0.253855        15500.0   \n",
        "149971   83                                     0     0.013997         5000.0   \n",
        "149972   42                                     0     0.008638         6945.0   \n",
        "149973   44                                     0     0.494819         5500.0   \n",
        "149974   61                                     2     0.603479         5000.0   \n",
        "149975   58                                     0  2716.000000            NaN   \n",
        "149976   76                                     0    60.000000            NaN   \n",
        "149977   29                                     0   349.000000            NaN   \n",
        "149978   52                                     2     0.259496         2500.0   \n",
        "149979   55                                     0     0.057235         8700.0   \n",
        "149980   64                                     0     0.254976         5525.0   \n",
        "149981   43                                     0     0.121752         6849.0   \n",
        "149982   37                                     0     0.250272         2760.0   \n",
        "149983   82                                     0     0.000800         5000.0   \n",
        "149984   84                                     0    25.000000            NaN   \n",
        "149985   26                                     0     0.324962         1950.0   \n",
        "149986   49                                     0     0.080384         5000.0   \n",
        "149987   28                                     0     0.055692         3249.0   \n",
        "149988   31                                     1     0.347924         7515.0   \n",
        "149989   62                                     0     0.001408         9233.0   \n",
        "149990   46                                     0     0.609779         4335.0   \n",
        "149991   59                                     0     0.477658        10316.0   \n",
        "149992   50                                     0  4132.000000            NaN   \n",
        "149993   22                                     0     0.000000          820.0   \n",
        "149994   50                                     0     0.404293         3400.0   \n",
        "149995   74                                     0     0.225131         2100.0   \n",
        "149996   44                                     0     0.716562         5584.0   \n",
        "149997   58                                     0  3870.000000            NaN   \n",
        "149998   30                                     0     0.000000         5716.0   \n",
        "149999   64                                     0     0.249908         8158.0   \n",
        "\n",
        "        NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
        "0                                    13                        0   \n",
        "1                                     4                        0   \n",
        "2                                     2                        1   \n",
        "3                                     5                        0   \n",
        "4                                     7                        0   \n",
        "5                                     3                        0   \n",
        "6                                     8                        0   \n",
        "7                                     8                        0   \n",
        "8                                     2                        0   \n",
        "9                                     9                        0   \n",
        "10                                    5                        0   \n",
        "11                                    7                        0   \n",
        "12                                   13                        0   \n",
        "13                                    9                        3   \n",
        "14                                    6                        0   \n",
        "15                                    7                        0   \n",
        "16                                   10                        0   \n",
        "17                                    7                        0   \n",
        "18                                    7                        0   \n",
        "19                                    2                        0   \n",
        "20                                   10                        0   \n",
        "21                                    7                        0   \n",
        "22                                    4                        0   \n",
        "23                                    6                        0   \n",
        "24                                    9                        0   \n",
        "25                                   14                        0   \n",
        "26                                   22                        0   \n",
        "27                                   17                        0   \n",
        "28                                    1                        0   \n",
        "29                                   15                        0   \n",
        "...                                 ...                      ...   \n",
        "149970                                7                        0   \n",
        "149971                                6                        0   \n",
        "149972                                3                        0   \n",
        "149973                                7                        0   \n",
        "149974                               11                        0   \n",
        "149975                                8                        0   \n",
        "149976                                5                        0   \n",
        "149977                                3                        0   \n",
        "149978                                4                        0   \n",
        "149979                                7                        0   \n",
        "149980                               12                        0   \n",
        "149981                                4                        0   \n",
        "149982                                8                        0   \n",
        "149983                                5                        0   \n",
        "149984                                5                        0   \n",
        "149985                                4                        0   \n",
        "149986                               16                        0   \n",
        "149987                                3                        1   \n",
        "149988                               10                        0   \n",
        "149989                                4                        0   \n",
        "149990                                7                        0   \n",
        "149991                               10                        0   \n",
        "149992                               11                        0   \n",
        "149993                                1                        0   \n",
        "149994                                7                        0   \n",
        "149995                                4                        0   \n",
        "149996                                4                        0   \n",
        "149997                               18                        0   \n",
        "149998                                4                        0   \n",
        "149999                                8                        0   \n",
        "\n",
        "        NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
        "0                                  6                                     0   \n",
        "1                                  0                                     0   \n",
        "2                                  0                                     0   \n",
        "3                                  0                                     0   \n",
        "4                                  1                                     0   \n",
        "5                                  1                                     0   \n",
        "6                                  3                                     0   \n",
        "7                                  0                                     0   \n",
        "8                                  0                                     0   \n",
        "9                                  4                                     0   \n",
        "10                                 0                                     0   \n",
        "11                                 2                                     0   \n",
        "12                                 2                                     0   \n",
        "13                                 1                                     1   \n",
        "14                                 1                                     0   \n",
        "15                                 1                                     0   \n",
        "16                                 2                                     0   \n",
        "17                                 0                                     0   \n",
        "18                                 1                                     0   \n",
        "19                                 0                                     0   \n",
        "20                                 2                                     0   \n",
        "21                                 1                                     0   \n",
        "22                                 0                                     0   \n",
        "23                                 0                                     0   \n",
        "24                                 1                                     0   \n",
        "25                                 3                                     0   \n",
        "26                                 1                                     0   \n",
        "27                                 0                                     0   \n",
        "28                                 0                                     0   \n",
        "29                                 1                                     0   \n",
        "...                              ...                                   ...   \n",
        "149970                             2                                     0   \n",
        "149971                             0                                     0   \n",
        "149972                             0                                     0   \n",
        "149973                             1                                     0   \n",
        "149974                             1                                     0   \n",
        "149975                             2                                     0   \n",
        "149976                             0                                     0   \n",
        "149977                             0                                     0   \n",
        "149978                             0                                     0   \n",
        "149979                             0                                     0   \n",
        "149980                             1                                     0   \n",
        "149981                             0                                     0   \n",
        "149982                             0                                     0   \n",
        "149983                             0                                     0   \n",
        "149984                             0                                     0   \n",
        "149985                             0                                     0   \n",
        "149986                             0                                     0   \n",
        "149987                             0                                     0   \n",
        "149988                             1                                     0   \n",
        "149989                             0                                     0   \n",
        "149990                             1                                     0   \n",
        "149991                             2                                     0   \n",
        "149992                             1                                     0   \n",
        "149993                             0                                     0   \n",
        "149994                             0                                     0   \n",
        "149995                             1                                     0   \n",
        "149996                             1                                     0   \n",
        "149997                             1                                     0   \n",
        "149998                             0                                     0   \n",
        "149999                             2                                     0   \n",
        "\n",
        "        NumberOfDependents  \n",
        "0                      2.0  \n",
        "1                      1.0  \n",
        "2                      0.0  \n",
        "3                      0.0  \n",
        "4                      0.0  \n",
        "5                      1.0  \n",
        "6                      0.0  \n",
        "7                      0.0  \n",
        "8                      NaN  \n",
        "9                      2.0  \n",
        "10                     0.0  \n",
        "11                     2.0  \n",
        "12                     2.0  \n",
        "13                     2.0  \n",
        "14                     0.0  \n",
        "15                     2.0  \n",
        "16                     0.0  \n",
        "17                     0.0  \n",
        "18                     2.0  \n",
        "19                     0.0  \n",
        "20                     0.0  \n",
        "21                     2.0  \n",
        "22                     0.0  \n",
        "23                     0.0  \n",
        "24                     0.0  \n",
        "25                     1.0  \n",
        "26                     0.0  \n",
        "27                     1.0  \n",
        "28                     0.0  \n",
        "29                     0.0  \n",
        "...                    ...  \n",
        "149970                 2.0  \n",
        "149971                 0.0  \n",
        "149972                 1.0  \n",
        "149973                 1.0  \n",
        "149974                 0.0  \n",
        "149975                 0.0  \n",
        "149976                 0.0  \n",
        "149977                 0.0  \n",
        "149978                 0.0  \n",
        "149979                 0.0  \n",
        "149980                 0.0  \n",
        "149981                 4.0  \n",
        "149982                 3.0  \n",
        "149983                 0.0  \n",
        "149984                 0.0  \n",
        "149985                 0.0  \n",
        "149986                 1.0  \n",
        "149987                 0.0  \n",
        "149988                 0.0  \n",
        "149989                 3.0  \n",
        "149990                 2.0  \n",
        "149991                 0.0  \n",
        "149992                 3.0  \n",
        "149993                 0.0  \n",
        "149994                 0.0  \n",
        "149995                 0.0  \n",
        "149996                 2.0  \n",
        "149997                 0.0  \n",
        "149998                 0.0  \n",
        "149999                 0.0  \n",
        "\n",
        "[150000 rows x 12 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On se rend compte que [pandas](http://pandas.pydata.org) cr\u00e9e automatiquement une colonne index qui fait double emploi avec la colonne anonyme du fichier csv.\n",
      "\n",
      "On d\u00e9cide donc d'utiliser directement cette colonne comme index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pd.read_csv(dataf,index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SeriousDlqin2yrs</th>\n",
        "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
        "      <th>age</th>\n",
        "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
        "      <th>DebtRatio</th>\n",
        "      <th>MonthlyIncome</th>\n",
        "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
        "      <th>NumberOfTimes90DaysLate</th>\n",
        "      <th>NumberRealEstateLoansOrLines</th>\n",
        "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
        "      <th>NumberOfDependents</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>0.766127</td>\n",
        "      <td>45</td>\n",
        "      <td>2</td>\n",
        "      <td>0.802982</td>\n",
        "      <td>9120.0</td>\n",
        "      <td>13</td>\n",
        "      <td>0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>0</td>\n",
        "      <td>0.957151</td>\n",
        "      <td>40</td>\n",
        "      <td>0</td>\n",
        "      <td>0.121876</td>\n",
        "      <td>2600.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>0</td>\n",
        "      <td>0.658180</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>0.085113</td>\n",
        "      <td>3042.0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0</td>\n",
        "      <td>0.233810</td>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.036050</td>\n",
        "      <td>3300.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>0</td>\n",
        "      <td>0.907239</td>\n",
        "      <td>49</td>\n",
        "      <td>1</td>\n",
        "      <td>0.024926</td>\n",
        "      <td>63588.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>0</td>\n",
        "      <td>0.213179</td>\n",
        "      <td>74</td>\n",
        "      <td>0</td>\n",
        "      <td>0.375607</td>\n",
        "      <td>3500.0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>0</td>\n",
        "      <td>0.305682</td>\n",
        "      <td>57</td>\n",
        "      <td>0</td>\n",
        "      <td>5710.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>0</td>\n",
        "      <td>0.754464</td>\n",
        "      <td>39</td>\n",
        "      <td>0</td>\n",
        "      <td>0.209940</td>\n",
        "      <td>3500.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>0</td>\n",
        "      <td>0.116951</td>\n",
        "      <td>27</td>\n",
        "      <td>0</td>\n",
        "      <td>46.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>0</td>\n",
        "      <td>0.189169</td>\n",
        "      <td>57</td>\n",
        "      <td>0</td>\n",
        "      <td>0.606291</td>\n",
        "      <td>23684.0</td>\n",
        "      <td>9</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>0</td>\n",
        "      <td>0.644226</td>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.309476</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>0</td>\n",
        "      <td>0.018798</td>\n",
        "      <td>51</td>\n",
        "      <td>0</td>\n",
        "      <td>0.531529</td>\n",
        "      <td>6501.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>0</td>\n",
        "      <td>0.010352</td>\n",
        "      <td>46</td>\n",
        "      <td>0</td>\n",
        "      <td>0.298354</td>\n",
        "      <td>12454.0</td>\n",
        "      <td>13</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>1</td>\n",
        "      <td>0.964673</td>\n",
        "      <td>40</td>\n",
        "      <td>3</td>\n",
        "      <td>0.382965</td>\n",
        "      <td>13700.0</td>\n",
        "      <td>9</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>0</td>\n",
        "      <td>0.019657</td>\n",
        "      <td>76</td>\n",
        "      <td>0</td>\n",
        "      <td>477.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>0</td>\n",
        "      <td>0.548458</td>\n",
        "      <td>64</td>\n",
        "      <td>0</td>\n",
        "      <td>0.209892</td>\n",
        "      <td>11362.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>0</td>\n",
        "      <td>0.061086</td>\n",
        "      <td>78</td>\n",
        "      <td>0</td>\n",
        "      <td>2058.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>0</td>\n",
        "      <td>0.166284</td>\n",
        "      <td>53</td>\n",
        "      <td>0</td>\n",
        "      <td>0.188274</td>\n",
        "      <td>8800.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>0</td>\n",
        "      <td>0.221813</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.527888</td>\n",
        "      <td>3280.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>0</td>\n",
        "      <td>0.602794</td>\n",
        "      <td>25</td>\n",
        "      <td>0</td>\n",
        "      <td>0.065868</td>\n",
        "      <td>333.0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>0</td>\n",
        "      <td>0.200923</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.430046</td>\n",
        "      <td>12300.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>1</td>\n",
        "      <td>0.025656</td>\n",
        "      <td>38</td>\n",
        "      <td>0</td>\n",
        "      <td>0.475841</td>\n",
        "      <td>3000.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>0</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>39</td>\n",
        "      <td>0</td>\n",
        "      <td>0.241104</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>0</td>\n",
        "      <td>0.075427</td>\n",
        "      <td>32</td>\n",
        "      <td>0</td>\n",
        "      <td>0.085512</td>\n",
        "      <td>7916.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>0</td>\n",
        "      <td>0.046560</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>0.241622</td>\n",
        "      <td>2416.0</td>\n",
        "      <td>9</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>1</td>\n",
        "      <td>0.392248</td>\n",
        "      <td>50</td>\n",
        "      <td>0</td>\n",
        "      <td>1.595253</td>\n",
        "      <td>4676.0</td>\n",
        "      <td>14</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>0</td>\n",
        "      <td>0.052436</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>0.097672</td>\n",
        "      <td>8333.0</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>0</td>\n",
        "      <td>0.034421</td>\n",
        "      <td>69</td>\n",
        "      <td>0</td>\n",
        "      <td>0.042383</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>17</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>0</td>\n",
        "      <td>0.452516</td>\n",
        "      <td>24</td>\n",
        "      <td>0</td>\n",
        "      <td>0.011761</td>\n",
        "      <td>3400.0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>0</td>\n",
        "      <td>0.392995</td>\n",
        "      <td>58</td>\n",
        "      <td>2</td>\n",
        "      <td>0.436103</td>\n",
        "      <td>5500.0</td>\n",
        "      <td>15</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149971</th>\n",
        "      <td>0</td>\n",
        "      <td>0.025449</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>0.253855</td>\n",
        "      <td>15500.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149972</th>\n",
        "      <td>0</td>\n",
        "      <td>0.058001</td>\n",
        "      <td>83</td>\n",
        "      <td>0</td>\n",
        "      <td>0.013997</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149973</th>\n",
        "      <td>0</td>\n",
        "      <td>0.071273</td>\n",
        "      <td>42</td>\n",
        "      <td>0</td>\n",
        "      <td>0.008638</td>\n",
        "      <td>6945.0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149974</th>\n",
        "      <td>0</td>\n",
        "      <td>1.026395</td>\n",
        "      <td>44</td>\n",
        "      <td>0</td>\n",
        "      <td>0.494819</td>\n",
        "      <td>5500.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149975</th>\n",
        "      <td>0</td>\n",
        "      <td>0.962721</td>\n",
        "      <td>61</td>\n",
        "      <td>2</td>\n",
        "      <td>0.603479</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>11</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149976</th>\n",
        "      <td>0</td>\n",
        "      <td>0.022088</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>2716.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149977</th>\n",
        "      <td>0</td>\n",
        "      <td>0.000627</td>\n",
        "      <td>76</td>\n",
        "      <td>0</td>\n",
        "      <td>60.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149978</th>\n",
        "      <td>0</td>\n",
        "      <td>0.236450</td>\n",
        "      <td>29</td>\n",
        "      <td>0</td>\n",
        "      <td>349.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149979</th>\n",
        "      <td>0</td>\n",
        "      <td>0.917635</td>\n",
        "      <td>52</td>\n",
        "      <td>2</td>\n",
        "      <td>0.259496</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149980</th>\n",
        "      <td>1</td>\n",
        "      <td>0.224711</td>\n",
        "      <td>55</td>\n",
        "      <td>0</td>\n",
        "      <td>0.057235</td>\n",
        "      <td>8700.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149981</th>\n",
        "      <td>0</td>\n",
        "      <td>0.067644</td>\n",
        "      <td>64</td>\n",
        "      <td>0</td>\n",
        "      <td>0.254976</td>\n",
        "      <td>5525.0</td>\n",
        "      <td>12</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149982</th>\n",
        "      <td>0</td>\n",
        "      <td>0.810012</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.121752</td>\n",
        "      <td>6849.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>4.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149983</th>\n",
        "      <td>0</td>\n",
        "      <td>0.021046</td>\n",
        "      <td>37</td>\n",
        "      <td>0</td>\n",
        "      <td>0.250272</td>\n",
        "      <td>2760.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149984</th>\n",
        "      <td>0</td>\n",
        "      <td>0.002485</td>\n",
        "      <td>82</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000800</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149985</th>\n",
        "      <td>0</td>\n",
        "      <td>0.037548</td>\n",
        "      <td>84</td>\n",
        "      <td>0</td>\n",
        "      <td>25.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149986</th>\n",
        "      <td>0</td>\n",
        "      <td>0.954409</td>\n",
        "      <td>26</td>\n",
        "      <td>0</td>\n",
        "      <td>0.324962</td>\n",
        "      <td>1950.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149987</th>\n",
        "      <td>0</td>\n",
        "      <td>0.168102</td>\n",
        "      <td>49</td>\n",
        "      <td>0</td>\n",
        "      <td>0.080384</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>16</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149988</th>\n",
        "      <td>0</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>28</td>\n",
        "      <td>0</td>\n",
        "      <td>0.055692</td>\n",
        "      <td>3249.0</td>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149989</th>\n",
        "      <td>0</td>\n",
        "      <td>0.902051</td>\n",
        "      <td>31</td>\n",
        "      <td>1</td>\n",
        "      <td>0.347924</td>\n",
        "      <td>7515.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149990</th>\n",
        "      <td>0</td>\n",
        "      <td>0.013356</td>\n",
        "      <td>62</td>\n",
        "      <td>0</td>\n",
        "      <td>0.001408</td>\n",
        "      <td>9233.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149991</th>\n",
        "      <td>0</td>\n",
        "      <td>0.055518</td>\n",
        "      <td>46</td>\n",
        "      <td>0</td>\n",
        "      <td>0.609779</td>\n",
        "      <td>4335.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149992</th>\n",
        "      <td>0</td>\n",
        "      <td>0.104112</td>\n",
        "      <td>59</td>\n",
        "      <td>0</td>\n",
        "      <td>0.477658</td>\n",
        "      <td>10316.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149993</th>\n",
        "      <td>0</td>\n",
        "      <td>0.871976</td>\n",
        "      <td>50</td>\n",
        "      <td>0</td>\n",
        "      <td>4132.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>11</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149994</th>\n",
        "      <td>0</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>820.0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149995</th>\n",
        "      <td>0</td>\n",
        "      <td>0.385742</td>\n",
        "      <td>50</td>\n",
        "      <td>0</td>\n",
        "      <td>0.404293</td>\n",
        "      <td>3400.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149996</th>\n",
        "      <td>0</td>\n",
        "      <td>0.040674</td>\n",
        "      <td>74</td>\n",
        "      <td>0</td>\n",
        "      <td>0.225131</td>\n",
        "      <td>2100.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149997</th>\n",
        "      <td>0</td>\n",
        "      <td>0.299745</td>\n",
        "      <td>44</td>\n",
        "      <td>0</td>\n",
        "      <td>0.716562</td>\n",
        "      <td>5584.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149998</th>\n",
        "      <td>0</td>\n",
        "      <td>0.246044</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>3870.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>18</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>149999</th>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>5716.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>150000</th>\n",
        "      <td>0</td>\n",
        "      <td>0.850283</td>\n",
        "      <td>64</td>\n",
        "      <td>0</td>\n",
        "      <td>0.249908</td>\n",
        "      <td>8158.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>150000 rows \u00d7 11 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "        SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
        "1                      1                              0.766127   45   \n",
        "2                      0                              0.957151   40   \n",
        "3                      0                              0.658180   38   \n",
        "4                      0                              0.233810   30   \n",
        "5                      0                              0.907239   49   \n",
        "6                      0                              0.213179   74   \n",
        "7                      0                              0.305682   57   \n",
        "8                      0                              0.754464   39   \n",
        "9                      0                              0.116951   27   \n",
        "10                     0                              0.189169   57   \n",
        "11                     0                              0.644226   30   \n",
        "12                     0                              0.018798   51   \n",
        "13                     0                              0.010352   46   \n",
        "14                     1                              0.964673   40   \n",
        "15                     0                              0.019657   76   \n",
        "16                     0                              0.548458   64   \n",
        "17                     0                              0.061086   78   \n",
        "18                     0                              0.166284   53   \n",
        "19                     0                              0.221813   43   \n",
        "20                     0                              0.602794   25   \n",
        "21                     0                              0.200923   43   \n",
        "22                     1                              0.025656   38   \n",
        "23                     0                              1.000000   39   \n",
        "24                     0                              0.075427   32   \n",
        "25                     0                              0.046560   58   \n",
        "26                     1                              0.392248   50   \n",
        "27                     0                              0.052436   58   \n",
        "28                     0                              0.034421   69   \n",
        "29                     0                              0.452516   24   \n",
        "30                     0                              0.392995   58   \n",
        "...                  ...                                   ...  ...   \n",
        "149971                 0                              0.025449   58   \n",
        "149972                 0                              0.058001   83   \n",
        "149973                 0                              0.071273   42   \n",
        "149974                 0                              1.026395   44   \n",
        "149975                 0                              0.962721   61   \n",
        "149976                 0                              0.022088   58   \n",
        "149977                 0                              0.000627   76   \n",
        "149978                 0                              0.236450   29   \n",
        "149979                 0                              0.917635   52   \n",
        "149980                 1                              0.224711   55   \n",
        "149981                 0                              0.067644   64   \n",
        "149982                 0                              0.810012   43   \n",
        "149983                 0                              0.021046   37   \n",
        "149984                 0                              0.002485   82   \n",
        "149985                 0                              0.037548   84   \n",
        "149986                 0                              0.954409   26   \n",
        "149987                 0                              0.168102   49   \n",
        "149988                 0                              1.000000   28   \n",
        "149989                 0                              0.902051   31   \n",
        "149990                 0                              0.013356   62   \n",
        "149991                 0                              0.055518   46   \n",
        "149992                 0                              0.104112   59   \n",
        "149993                 0                              0.871976   50   \n",
        "149994                 0                              1.000000   22   \n",
        "149995                 0                              0.385742   50   \n",
        "149996                 0                              0.040674   74   \n",
        "149997                 0                              0.299745   44   \n",
        "149998                 0                              0.246044   58   \n",
        "149999                 0                              0.000000   30   \n",
        "150000                 0                              0.850283   64   \n",
        "\n",
        "        NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  MonthlyIncome  \\\n",
        "1                                          2     0.802982         9120.0   \n",
        "2                                          0     0.121876         2600.0   \n",
        "3                                          1     0.085113         3042.0   \n",
        "4                                          0     0.036050         3300.0   \n",
        "5                                          1     0.024926        63588.0   \n",
        "6                                          0     0.375607         3500.0   \n",
        "7                                          0  5710.000000            NaN   \n",
        "8                                          0     0.209940         3500.0   \n",
        "9                                          0    46.000000            NaN   \n",
        "10                                         0     0.606291        23684.0   \n",
        "11                                         0     0.309476         2500.0   \n",
        "12                                         0     0.531529         6501.0   \n",
        "13                                         0     0.298354        12454.0   \n",
        "14                                         3     0.382965        13700.0   \n",
        "15                                         0   477.000000            0.0   \n",
        "16                                         0     0.209892        11362.0   \n",
        "17                                         0  2058.000000            NaN   \n",
        "18                                         0     0.188274         8800.0   \n",
        "19                                         0     0.527888         3280.0   \n",
        "20                                         0     0.065868          333.0   \n",
        "21                                         0     0.430046        12300.0   \n",
        "22                                         0     0.475841         3000.0   \n",
        "23                                         0     0.241104         2500.0   \n",
        "24                                         0     0.085512         7916.0   \n",
        "25                                         0     0.241622         2416.0   \n",
        "26                                         0     1.595253         4676.0   \n",
        "27                                         0     0.097672         8333.0   \n",
        "28                                         0     0.042383         2500.0   \n",
        "29                                         0     0.011761         3400.0   \n",
        "30                                         2     0.436103         5500.0   \n",
        "...                                      ...          ...            ...   \n",
        "149971                                     0     0.253855        15500.0   \n",
        "149972                                     0     0.013997         5000.0   \n",
        "149973                                     0     0.008638         6945.0   \n",
        "149974                                     0     0.494819         5500.0   \n",
        "149975                                     2     0.603479         5000.0   \n",
        "149976                                     0  2716.000000            NaN   \n",
        "149977                                     0    60.000000            NaN   \n",
        "149978                                     0   349.000000            NaN   \n",
        "149979                                     2     0.259496         2500.0   \n",
        "149980                                     0     0.057235         8700.0   \n",
        "149981                                     0     0.254976         5525.0   \n",
        "149982                                     0     0.121752         6849.0   \n",
        "149983                                     0     0.250272         2760.0   \n",
        "149984                                     0     0.000800         5000.0   \n",
        "149985                                     0    25.000000            NaN   \n",
        "149986                                     0     0.324962         1950.0   \n",
        "149987                                     0     0.080384         5000.0   \n",
        "149988                                     0     0.055692         3249.0   \n",
        "149989                                     1     0.347924         7515.0   \n",
        "149990                                     0     0.001408         9233.0   \n",
        "149991                                     0     0.609779         4335.0   \n",
        "149992                                     0     0.477658        10316.0   \n",
        "149993                                     0  4132.000000            NaN   \n",
        "149994                                     0     0.000000          820.0   \n",
        "149995                                     0     0.404293         3400.0   \n",
        "149996                                     0     0.225131         2100.0   \n",
        "149997                                     0     0.716562         5584.0   \n",
        "149998                                     0  3870.000000            NaN   \n",
        "149999                                     0     0.000000         5716.0   \n",
        "150000                                     0     0.249908         8158.0   \n",
        "\n",
        "        NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
        "1                                    13                        0   \n",
        "2                                     4                        0   \n",
        "3                                     2                        1   \n",
        "4                                     5                        0   \n",
        "5                                     7                        0   \n",
        "6                                     3                        0   \n",
        "7                                     8                        0   \n",
        "8                                     8                        0   \n",
        "9                                     2                        0   \n",
        "10                                    9                        0   \n",
        "11                                    5                        0   \n",
        "12                                    7                        0   \n",
        "13                                   13                        0   \n",
        "14                                    9                        3   \n",
        "15                                    6                        0   \n",
        "16                                    7                        0   \n",
        "17                                   10                        0   \n",
        "18                                    7                        0   \n",
        "19                                    7                        0   \n",
        "20                                    2                        0   \n",
        "21                                   10                        0   \n",
        "22                                    7                        0   \n",
        "23                                    4                        0   \n",
        "24                                    6                        0   \n",
        "25                                    9                        0   \n",
        "26                                   14                        0   \n",
        "27                                   22                        0   \n",
        "28                                   17                        0   \n",
        "29                                    1                        0   \n",
        "30                                   15                        0   \n",
        "...                                 ...                      ...   \n",
        "149971                                7                        0   \n",
        "149972                                6                        0   \n",
        "149973                                3                        0   \n",
        "149974                                7                        0   \n",
        "149975                               11                        0   \n",
        "149976                                8                        0   \n",
        "149977                                5                        0   \n",
        "149978                                3                        0   \n",
        "149979                                4                        0   \n",
        "149980                                7                        0   \n",
        "149981                               12                        0   \n",
        "149982                                4                        0   \n",
        "149983                                8                        0   \n",
        "149984                                5                        0   \n",
        "149985                                5                        0   \n",
        "149986                                4                        0   \n",
        "149987                               16                        0   \n",
        "149988                                3                        1   \n",
        "149989                               10                        0   \n",
        "149990                                4                        0   \n",
        "149991                                7                        0   \n",
        "149992                               10                        0   \n",
        "149993                               11                        0   \n",
        "149994                                1                        0   \n",
        "149995                                7                        0   \n",
        "149996                                4                        0   \n",
        "149997                                4                        0   \n",
        "149998                               18                        0   \n",
        "149999                                4                        0   \n",
        "150000                                8                        0   \n",
        "\n",
        "        NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
        "1                                  6                                     0   \n",
        "2                                  0                                     0   \n",
        "3                                  0                                     0   \n",
        "4                                  0                                     0   \n",
        "5                                  1                                     0   \n",
        "6                                  1                                     0   \n",
        "7                                  3                                     0   \n",
        "8                                  0                                     0   \n",
        "9                                  0                                     0   \n",
        "10                                 4                                     0   \n",
        "11                                 0                                     0   \n",
        "12                                 2                                     0   \n",
        "13                                 2                                     0   \n",
        "14                                 1                                     1   \n",
        "15                                 1                                     0   \n",
        "16                                 1                                     0   \n",
        "17                                 2                                     0   \n",
        "18                                 0                                     0   \n",
        "19                                 1                                     0   \n",
        "20                                 0                                     0   \n",
        "21                                 2                                     0   \n",
        "22                                 1                                     0   \n",
        "23                                 0                                     0   \n",
        "24                                 0                                     0   \n",
        "25                                 1                                     0   \n",
        "26                                 3                                     0   \n",
        "27                                 1                                     0   \n",
        "28                                 0                                     0   \n",
        "29                                 0                                     0   \n",
        "30                                 1                                     0   \n",
        "...                              ...                                   ...   \n",
        "149971                             2                                     0   \n",
        "149972                             0                                     0   \n",
        "149973                             0                                     0   \n",
        "149974                             1                                     0   \n",
        "149975                             1                                     0   \n",
        "149976                             2                                     0   \n",
        "149977                             0                                     0   \n",
        "149978                             0                                     0   \n",
        "149979                             0                                     0   \n",
        "149980                             0                                     0   \n",
        "149981                             1                                     0   \n",
        "149982                             0                                     0   \n",
        "149983                             0                                     0   \n",
        "149984                             0                                     0   \n",
        "149985                             0                                     0   \n",
        "149986                             0                                     0   \n",
        "149987                             0                                     0   \n",
        "149988                             0                                     0   \n",
        "149989                             1                                     0   \n",
        "149990                             0                                     0   \n",
        "149991                             1                                     0   \n",
        "149992                             2                                     0   \n",
        "149993                             1                                     0   \n",
        "149994                             0                                     0   \n",
        "149995                             0                                     0   \n",
        "149996                             1                                     0   \n",
        "149997                             1                                     0   \n",
        "149998                             1                                     0   \n",
        "149999                             0                                     0   \n",
        "150000                             2                                     0   \n",
        "\n",
        "        NumberOfDependents  \n",
        "1                      2.0  \n",
        "2                      1.0  \n",
        "3                      0.0  \n",
        "4                      0.0  \n",
        "5                      0.0  \n",
        "6                      1.0  \n",
        "7                      0.0  \n",
        "8                      0.0  \n",
        "9                      NaN  \n",
        "10                     2.0  \n",
        "11                     0.0  \n",
        "12                     2.0  \n",
        "13                     2.0  \n",
        "14                     2.0  \n",
        "15                     0.0  \n",
        "16                     2.0  \n",
        "17                     0.0  \n",
        "18                     0.0  \n",
        "19                     2.0  \n",
        "20                     0.0  \n",
        "21                     0.0  \n",
        "22                     2.0  \n",
        "23                     0.0  \n",
        "24                     0.0  \n",
        "25                     0.0  \n",
        "26                     1.0  \n",
        "27                     0.0  \n",
        "28                     1.0  \n",
        "29                     0.0  \n",
        "30                     0.0  \n",
        "...                    ...  \n",
        "149971                 2.0  \n",
        "149972                 0.0  \n",
        "149973                 1.0  \n",
        "149974                 1.0  \n",
        "149975                 0.0  \n",
        "149976                 0.0  \n",
        "149977                 0.0  \n",
        "149978                 0.0  \n",
        "149979                 0.0  \n",
        "149980                 0.0  \n",
        "149981                 0.0  \n",
        "149982                 4.0  \n",
        "149983                 3.0  \n",
        "149984                 0.0  \n",
        "149985                 0.0  \n",
        "149986                 0.0  \n",
        "149987                 1.0  \n",
        "149988                 0.0  \n",
        "149989                 0.0  \n",
        "149990                 3.0  \n",
        "149991                 2.0  \n",
        "149992                 0.0  \n",
        "149993                 3.0  \n",
        "149994                 0.0  \n",
        "149995                 0.0  \n",
        "149996                 0.0  \n",
        "149997                 2.0  \n",
        "149998                 0.0  \n",
        "149999                 0.0  \n",
        "150000                 0.0  \n",
        "\n",
        "[150000 rows x 11 columns]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On enregistre le r\u00e9sultat dans `train`. Comme dans le code R."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aTuple = (123, 'xyz', 'zara', 'abc');\n",
      "list(aTuple)\n",
      "#inutile, mais parfois python ne reconnait plus la fonction list() !!!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[123, 'xyz', 'zara', 'abc']"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = pd.read_csv(dataf,index_col=0)\n",
      "features_names = list(train)[1:]\n",
      "test = pd.read_csv(testf,index_col=0)\n",
      "pd.read_csv(testf,index_col=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SeriousDlqin2yrs</th>\n",
        "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
        "      <th>age</th>\n",
        "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
        "      <th>DebtRatio</th>\n",
        "      <th>MonthlyIncome</th>\n",
        "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
        "      <th>NumberOfTimes90DaysLate</th>\n",
        "      <th>NumberRealEstateLoansOrLines</th>\n",
        "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
        "      <th>NumberOfDependents</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.885519</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.177513</td>\n",
        "      <td>5700.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.463295</td>\n",
        "      <td>57</td>\n",
        "      <td>0</td>\n",
        "      <td>0.527237</td>\n",
        "      <td>9141.0</td>\n",
        "      <td>15</td>\n",
        "      <td>0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.043275</td>\n",
        "      <td>59</td>\n",
        "      <td>0</td>\n",
        "      <td>0.687648</td>\n",
        "      <td>5083.0</td>\n",
        "      <td>12</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.280308</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>0.925961</td>\n",
        "      <td>3200.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>NaN</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>27</td>\n",
        "      <td>0</td>\n",
        "      <td>0.019917</td>\n",
        "      <td>3865.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.509791</td>\n",
        "      <td>63</td>\n",
        "      <td>0</td>\n",
        "      <td>0.342429</td>\n",
        "      <td>4140.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.587778</td>\n",
        "      <td>50</td>\n",
        "      <td>0</td>\n",
        "      <td>1048.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.046149</td>\n",
        "      <td>79</td>\n",
        "      <td>1</td>\n",
        "      <td>0.369170</td>\n",
        "      <td>3301.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.013527</td>\n",
        "      <td>68</td>\n",
        "      <td>0</td>\n",
        "      <td>2024.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td>NaN</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>23</td>\n",
        "      <td>98</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.0</td>\n",
        "      <td>0</td>\n",
        "      <td>98</td>\n",
        "      <td>0</td>\n",
        "      <td>98</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.028485</td>\n",
        "      <td>37</td>\n",
        "      <td>0</td>\n",
        "      <td>0.319687</td>\n",
        "      <td>7400.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.085077</td>\n",
        "      <td>52</td>\n",
        "      <td>0</td>\n",
        "      <td>0.903552</td>\n",
        "      <td>4250.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.010596</td>\n",
        "      <td>68</td>\n",
        "      <td>0</td>\n",
        "      <td>0.007782</td>\n",
        "      <td>3854.0</td>\n",
        "      <td>16</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.380679</td>\n",
        "      <td>30</td>\n",
        "      <td>0</td>\n",
        "      <td>0.377449</td>\n",
        "      <td>2500.0</td>\n",
        "      <td>12</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.556894</td>\n",
        "      <td>56</td>\n",
        "      <td>0</td>\n",
        "      <td>0.697347</td>\n",
        "      <td>6822.0</td>\n",
        "      <td>14</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.079056</td>\n",
        "      <td>28</td>\n",
        "      <td>0</td>\n",
        "      <td>0.105831</td>\n",
        "      <td>7133.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.543013</td>\n",
        "      <td>72</td>\n",
        "      <td>0</td>\n",
        "      <td>0.461786</td>\n",
        "      <td>5900.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.112346</td>\n",
        "      <td>37</td>\n",
        "      <td>0</td>\n",
        "      <td>0.144326</td>\n",
        "      <td>2916.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.648285</td>\n",
        "      <td>29</td>\n",
        "      <td>0</td>\n",
        "      <td>0.174850</td>\n",
        "      <td>4500.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.686406</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>487.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.085910</td>\n",
        "      <td>48</td>\n",
        "      <td>0</td>\n",
        "      <td>0.196156</td>\n",
        "      <td>8844.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.158549</td>\n",
        "      <td>61</td>\n",
        "      <td>0</td>\n",
        "      <td>0.353158</td>\n",
        "      <td>11920.0</td>\n",
        "      <td>13</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.009303</td>\n",
        "      <td>69</td>\n",
        "      <td>0</td>\n",
        "      <td>0.384451</td>\n",
        "      <td>6083.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.957442</td>\n",
        "      <td>69</td>\n",
        "      <td>2</td>\n",
        "      <td>0.666338</td>\n",
        "      <td>3041.0</td>\n",
        "      <td>8</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.442489</td>\n",
        "      <td>50</td>\n",
        "      <td>1</td>\n",
        "      <td>0.286555</td>\n",
        "      <td>8500.0</td>\n",
        "      <td>17</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.125267</td>\n",
        "      <td>51</td>\n",
        "      <td>0</td>\n",
        "      <td>3825.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td>NaN</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>45</td>\n",
        "      <td>0</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>4750.0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.181481</td>\n",
        "      <td>67</td>\n",
        "      <td>0</td>\n",
        "      <td>1509.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>12</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.729397</td>\n",
        "      <td>34</td>\n",
        "      <td>0</td>\n",
        "      <td>0.335555</td>\n",
        "      <td>7500.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.024445</td>\n",
        "      <td>47</td>\n",
        "      <td>0</td>\n",
        "      <td>5810.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>20</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101474</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.662634</td>\n",
        "      <td>73</td>\n",
        "      <td>0</td>\n",
        "      <td>0.277090</td>\n",
        "      <td>5333.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101475</th>\n",
        "      <td>NaN</td>\n",
        "      <td>1.032484</td>\n",
        "      <td>47</td>\n",
        "      <td>0</td>\n",
        "      <td>0.365243</td>\n",
        "      <td>2036.0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101476</th>\n",
        "      <td>NaN</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>35</td>\n",
        "      <td>0</td>\n",
        "      <td>0.240467</td>\n",
        "      <td>1284.0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101477</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.015908</td>\n",
        "      <td>68</td>\n",
        "      <td>0</td>\n",
        "      <td>0.217593</td>\n",
        "      <td>8400.0</td>\n",
        "      <td>11</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101478</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.096295</td>\n",
        "      <td>69</td>\n",
        "      <td>0</td>\n",
        "      <td>0.052316</td>\n",
        "      <td>3000.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101479</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>43</td>\n",
        "      <td>0</td>\n",
        "      <td>0.095303</td>\n",
        "      <td>5833.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101480</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.024788</td>\n",
        "      <td>71</td>\n",
        "      <td>0</td>\n",
        "      <td>0.361319</td>\n",
        "      <td>3608.0</td>\n",
        "      <td>22</td>\n",
        "      <td>1</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101481</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.217134</td>\n",
        "      <td>48</td>\n",
        "      <td>0</td>\n",
        "      <td>0.602701</td>\n",
        "      <td>5257.0</td>\n",
        "      <td>15</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101482</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.048971</td>\n",
        "      <td>51</td>\n",
        "      <td>0</td>\n",
        "      <td>0.339154</td>\n",
        "      <td>7043.0</td>\n",
        "      <td>14</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101483</th>\n",
        "      <td>NaN</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>33</td>\n",
        "      <td>98</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>2000.0</td>\n",
        "      <td>0</td>\n",
        "      <td>98</td>\n",
        "      <td>0</td>\n",
        "      <td>98</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101484</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.124484</td>\n",
        "      <td>82</td>\n",
        "      <td>0</td>\n",
        "      <td>0.003797</td>\n",
        "      <td>7636.0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101485</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.065636</td>\n",
        "      <td>60</td>\n",
        "      <td>0</td>\n",
        "      <td>0.306759</td>\n",
        "      <td>7500.0</td>\n",
        "      <td>10</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101486</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.043139</td>\n",
        "      <td>81</td>\n",
        "      <td>0</td>\n",
        "      <td>0.014548</td>\n",
        "      <td>3917.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101487</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.078280</td>\n",
        "      <td>55</td>\n",
        "      <td>0</td>\n",
        "      <td>0.495979</td>\n",
        "      <td>2983.0</td>\n",
        "      <td>16</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101488</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.000961</td>\n",
        "      <td>64</td>\n",
        "      <td>0</td>\n",
        "      <td>2.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101489</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.179587</td>\n",
        "      <td>68</td>\n",
        "      <td>0</td>\n",
        "      <td>0.268839</td>\n",
        "      <td>7550.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101490</th>\n",
        "      <td>NaN</td>\n",
        "      <td>1.031359</td>\n",
        "      <td>34</td>\n",
        "      <td>0</td>\n",
        "      <td>0.305339</td>\n",
        "      <td>3333.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101491</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.875649</td>\n",
        "      <td>43</td>\n",
        "      <td>2</td>\n",
        "      <td>0.512893</td>\n",
        "      <td>9500.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101492</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.228665</td>\n",
        "      <td>44</td>\n",
        "      <td>1</td>\n",
        "      <td>0.080143</td>\n",
        "      <td>8958.0</td>\n",
        "      <td>6</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101493</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.139191</td>\n",
        "      <td>58</td>\n",
        "      <td>1</td>\n",
        "      <td>3.183267</td>\n",
        "      <td>501.0</td>\n",
        "      <td>11</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101494</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.035549</td>\n",
        "      <td>58</td>\n",
        "      <td>0</td>\n",
        "      <td>0.290323</td>\n",
        "      <td>11128.0</td>\n",
        "      <td>7</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101495</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.218356</td>\n",
        "      <td>56</td>\n",
        "      <td>0</td>\n",
        "      <td>0.295803</td>\n",
        "      <td>1500.0</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101496</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.718874</td>\n",
        "      <td>35</td>\n",
        "      <td>1</td>\n",
        "      <td>0.308047</td>\n",
        "      <td>4125.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>2.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101497</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.021654</td>\n",
        "      <td>78</td>\n",
        "      <td>0</td>\n",
        "      <td>18.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101498</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.045230</td>\n",
        "      <td>67</td>\n",
        "      <td>0</td>\n",
        "      <td>0.012198</td>\n",
        "      <td>5000.0</td>\n",
        "      <td>4</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101499</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.282653</td>\n",
        "      <td>24</td>\n",
        "      <td>0</td>\n",
        "      <td>0.068522</td>\n",
        "      <td>1400.0</td>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101500</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.922156</td>\n",
        "      <td>36</td>\n",
        "      <td>3</td>\n",
        "      <td>0.934217</td>\n",
        "      <td>7615.0</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>0</td>\n",
        "      <td>4.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101501</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.081596</td>\n",
        "      <td>70</td>\n",
        "      <td>0</td>\n",
        "      <td>836.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>3</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101502</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.335457</td>\n",
        "      <td>56</td>\n",
        "      <td>0</td>\n",
        "      <td>3568.000000</td>\n",
        "      <td>NaN</td>\n",
        "      <td>8</td>\n",
        "      <td>0</td>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>3.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>101503</th>\n",
        "      <td>NaN</td>\n",
        "      <td>0.441842</td>\n",
        "      <td>29</td>\n",
        "      <td>0</td>\n",
        "      <td>0.198918</td>\n",
        "      <td>5916.0</td>\n",
        "      <td>12</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0.0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>101503 rows \u00d7 11 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "        SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
        "1                    NaN                              0.885519   43   \n",
        "2                    NaN                              0.463295   57   \n",
        "3                    NaN                              0.043275   59   \n",
        "4                    NaN                              0.280308   38   \n",
        "5                    NaN                              1.000000   27   \n",
        "6                    NaN                              0.509791   63   \n",
        "7                    NaN                              0.587778   50   \n",
        "8                    NaN                              0.046149   79   \n",
        "9                    NaN                              0.013527   68   \n",
        "10                   NaN                              1.000000   23   \n",
        "11                   NaN                              0.028485   37   \n",
        "12                   NaN                              0.085077   52   \n",
        "13                   NaN                              0.010596   68   \n",
        "14                   NaN                              0.380679   30   \n",
        "15                   NaN                              0.556894   56   \n",
        "16                   NaN                              0.079056   28   \n",
        "17                   NaN                              0.543013   72   \n",
        "18                   NaN                              0.112346   37   \n",
        "19                   NaN                              0.648285   29   \n",
        "20                   NaN                              0.686406   43   \n",
        "21                   NaN                              0.085910   48   \n",
        "22                   NaN                              0.158549   61   \n",
        "23                   NaN                              0.009303   69   \n",
        "24                   NaN                              0.957442   69   \n",
        "25                   NaN                              0.442489   50   \n",
        "26                   NaN                              0.125267   51   \n",
        "27                   NaN                              1.000000   45   \n",
        "28                   NaN                              0.181481   67   \n",
        "29                   NaN                              0.729397   34   \n",
        "30                   NaN                              0.024445   47   \n",
        "...                  ...                                   ...  ...   \n",
        "101474               NaN                              0.662634   73   \n",
        "101475               NaN                              1.032484   47   \n",
        "101476               NaN                              1.000000   35   \n",
        "101477               NaN                              0.015908   68   \n",
        "101478               NaN                              0.096295   69   \n",
        "101479               NaN                              0.000000   43   \n",
        "101480               NaN                              0.024788   71   \n",
        "101481               NaN                              0.217134   48   \n",
        "101482               NaN                              0.048971   51   \n",
        "101483               NaN                              1.000000   33   \n",
        "101484               NaN                              0.124484   82   \n",
        "101485               NaN                              0.065636   60   \n",
        "101486               NaN                              0.043139   81   \n",
        "101487               NaN                              0.078280   55   \n",
        "101488               NaN                              0.000961   64   \n",
        "101489               NaN                              0.179587   68   \n",
        "101490               NaN                              1.031359   34   \n",
        "101491               NaN                              0.875649   43   \n",
        "101492               NaN                              0.228665   44   \n",
        "101493               NaN                              0.139191   58   \n",
        "101494               NaN                              0.035549   58   \n",
        "101495               NaN                              0.218356   56   \n",
        "101496               NaN                              0.718874   35   \n",
        "101497               NaN                              0.021654   78   \n",
        "101498               NaN                              0.045230   67   \n",
        "101499               NaN                              0.282653   24   \n",
        "101500               NaN                              0.922156   36   \n",
        "101501               NaN                              0.081596   70   \n",
        "101502               NaN                              0.335457   56   \n",
        "101503               NaN                              0.441842   29   \n",
        "\n",
        "        NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  MonthlyIncome  \\\n",
        "1                                          0     0.177513         5700.0   \n",
        "2                                          0     0.527237         9141.0   \n",
        "3                                          0     0.687648         5083.0   \n",
        "4                                          1     0.925961         3200.0   \n",
        "5                                          0     0.019917         3865.0   \n",
        "6                                          0     0.342429         4140.0   \n",
        "7                                          0  1048.000000            0.0   \n",
        "8                                          1     0.369170         3301.0   \n",
        "9                                          0  2024.000000            NaN   \n",
        "10                                        98     0.000000            0.0   \n",
        "11                                         0     0.319687         7400.0   \n",
        "12                                         0     0.903552         4250.0   \n",
        "13                                         0     0.007782         3854.0   \n",
        "14                                         0     0.377449         2500.0   \n",
        "15                                         0     0.697347         6822.0   \n",
        "16                                         0     0.105831         7133.0   \n",
        "17                                         0     0.461786         5900.0   \n",
        "18                                         0     0.144326         2916.0   \n",
        "19                                         0     0.174850         4500.0   \n",
        "20                                         0   487.000000            NaN   \n",
        "21                                         0     0.196156         8844.0   \n",
        "22                                         0     0.353158        11920.0   \n",
        "23                                         0     0.384451         6083.0   \n",
        "24                                         2     0.666338         3041.0   \n",
        "25                                         1     0.286555         8500.0   \n",
        "26                                         0  3825.000000            NaN   \n",
        "27                                         0     0.000000         4750.0   \n",
        "28                                         0  1509.000000            NaN   \n",
        "29                                         0     0.335555         7500.0   \n",
        "30                                         0  5810.000000            NaN   \n",
        "...                                      ...          ...            ...   \n",
        "101474                                     0     0.277090         5333.0   \n",
        "101475                                     0     0.365243         2036.0   \n",
        "101476                                     0     0.240467         1284.0   \n",
        "101477                                     0     0.217593         8400.0   \n",
        "101478                                     0     0.052316         3000.0   \n",
        "101479                                     0     0.095303         5833.0   \n",
        "101480                                     0     0.361319         3608.0   \n",
        "101481                                     0     0.602701         5257.0   \n",
        "101482                                     0     0.339154         7043.0   \n",
        "101483                                    98     0.000000         2000.0   \n",
        "101484                                     0     0.003797         7636.0   \n",
        "101485                                     0     0.306759         7500.0   \n",
        "101486                                     0     0.014548         3917.0   \n",
        "101487                                     0     0.495979         2983.0   \n",
        "101488                                     0     2.000000            NaN   \n",
        "101489                                     0     0.268839         7550.0   \n",
        "101490                                     0     0.305339         3333.0   \n",
        "101491                                     2     0.512893         9500.0   \n",
        "101492                                     1     0.080143         8958.0   \n",
        "101493                                     1     3.183267          501.0   \n",
        "101494                                     0     0.290323        11128.0   \n",
        "101495                                     0     0.295803         1500.0   \n",
        "101496                                     1     0.308047         4125.0   \n",
        "101497                                     0    18.000000            NaN   \n",
        "101498                                     0     0.012198         5000.0   \n",
        "101499                                     0     0.068522         1400.0   \n",
        "101500                                     3     0.934217         7615.0   \n",
        "101501                                     0   836.000000            NaN   \n",
        "101502                                     0  3568.000000            NaN   \n",
        "101503                                     0     0.198918         5916.0   \n",
        "\n",
        "        NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
        "1                                     4                        0   \n",
        "2                                    15                        0   \n",
        "3                                    12                        0   \n",
        "4                                     7                        0   \n",
        "5                                     4                        0   \n",
        "6                                     4                        0   \n",
        "7                                     5                        0   \n",
        "8                                     8                        0   \n",
        "9                                     4                        0   \n",
        "10                                    0                       98   \n",
        "11                                    8                        0   \n",
        "12                                    6                        0   \n",
        "13                                   16                        0   \n",
        "14                                   12                        0   \n",
        "15                                   14                        0   \n",
        "16                                    8                        0   \n",
        "17                                   10                        0   \n",
        "18                                    7                        0   \n",
        "19                                    4                        0   \n",
        "20                                   10                        0   \n",
        "21                                    8                        0   \n",
        "22                                   13                        0   \n",
        "23                                    4                        0   \n",
        "24                                    8                        1   \n",
        "25                                   17                        0   \n",
        "26                                   10                        0   \n",
        "27                                    1                        0   \n",
        "28                                   12                        0   \n",
        "29                                    6                        0   \n",
        "30                                   20                        0   \n",
        "...                                 ...                      ...   \n",
        "101474                               10                        0   \n",
        "101475                                2                        0   \n",
        "101476                                1                        0   \n",
        "101477                               11                        0   \n",
        "101478                                4                        0   \n",
        "101479                                6                        0   \n",
        "101480                               22                        1   \n",
        "101481                               15                        0   \n",
        "101482                               14                        0   \n",
        "101483                                0                       98   \n",
        "101484                                2                        0   \n",
        "101485                               10                        0   \n",
        "101486                                4                        0   \n",
        "101487                               16                        0   \n",
        "101488                                5                        0   \n",
        "101489                                8                        0   \n",
        "101490                                6                        0   \n",
        "101491                                8                        0   \n",
        "101492                                6                        0   \n",
        "101493                               11                        0   \n",
        "101494                                7                        0   \n",
        "101495                                3                        0   \n",
        "101496                                8                        0   \n",
        "101497                                8                        0   \n",
        "101498                                4                        0   \n",
        "101499                                5                        0   \n",
        "101500                                8                        0   \n",
        "101501                                3                        0   \n",
        "101502                                8                        0   \n",
        "101503                               12                        0   \n",
        "\n",
        "        NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
        "1                                  0                                     0   \n",
        "2                                  4                                     0   \n",
        "3                                  1                                     0   \n",
        "4                                  2                                     0   \n",
        "5                                  0                                     0   \n",
        "6                                  0                                     0   \n",
        "7                                  0                                     0   \n",
        "8                                  1                                     0   \n",
        "9                                  1                                     0   \n",
        "10                                 0                                    98   \n",
        "11                                 1                                     0   \n",
        "12                                 2                                     0   \n",
        "13                                 0                                     0   \n",
        "14                                 0                                     0   \n",
        "15                                 1                                     0   \n",
        "16                                 0                                     0   \n",
        "17                                 2                                     0   \n",
        "18                                 0                                     0   \n",
        "19                                 0                                     1   \n",
        "20                                 0                                     0   \n",
        "21                                 1                                     0   \n",
        "22                                 1                                     0   \n",
        "23                                 2                                     0   \n",
        "24                                 1                                     1   \n",
        "25                                 1                                     0   \n",
        "26                                 2                                     0   \n",
        "27                                 0                                     0   \n",
        "28                                 1                                     0   \n",
        "29                                 2                                     0   \n",
        "30                                 2                                     0   \n",
        "...                              ...                                   ...   \n",
        "101474                             0                                     0   \n",
        "101475                             0                                     1   \n",
        "101476                             0                                     0   \n",
        "101477                             2                                     0   \n",
        "101478                             0                                     0   \n",
        "101479                             1                                     0   \n",
        "101480                             2                                     0   \n",
        "101481                             1                                     0   \n",
        "101482                             1                                     0   \n",
        "101483                             0                                    98   \n",
        "101484                             0                                     0   \n",
        "101485                             3                                     0   \n",
        "101486                             0                                     0   \n",
        "101487                             2                                     0   \n",
        "101488                             0                                     0   \n",
        "101489                             1                                     0   \n",
        "101490                             0                                     0   \n",
        "101491                             5                                     0   \n",
        "101492                             0                                     0   \n",
        "101493                             1                                     0   \n",
        "101494                             2                                     0   \n",
        "101495                             0                                     0   \n",
        "101496                             0                                     1   \n",
        "101497                             0                                     0   \n",
        "101498                             0                                     0   \n",
        "101499                             0                                     0   \n",
        "101500                             2                                     0   \n",
        "101501                             0                                     0   \n",
        "101502                             2                                     1   \n",
        "101503                             0                                     0   \n",
        "\n",
        "        NumberOfDependents  \n",
        "1                      0.0  \n",
        "2                      2.0  \n",
        "3                      2.0  \n",
        "4                      0.0  \n",
        "5                      1.0  \n",
        "6                      1.0  \n",
        "7                      3.0  \n",
        "8                      1.0  \n",
        "9                      0.0  \n",
        "10                     0.0  \n",
        "11                     1.0  \n",
        "12                     0.0  \n",
        "13                     0.0  \n",
        "14                     1.0  \n",
        "15                     1.0  \n",
        "16                     0.0  \n",
        "17                     1.0  \n",
        "18                     0.0  \n",
        "19                     1.0  \n",
        "20                     1.0  \n",
        "21                     1.0  \n",
        "22                     0.0  \n",
        "23                     0.0  \n",
        "24                     1.0  \n",
        "25                     2.0  \n",
        "26                     0.0  \n",
        "27                     1.0  \n",
        "28                     0.0  \n",
        "29                     1.0  \n",
        "30                     2.0  \n",
        "...                    ...  \n",
        "101474                 0.0  \n",
        "101475                 0.0  \n",
        "101476                 2.0  \n",
        "101477                 1.0  \n",
        "101478                 0.0  \n",
        "101479                 2.0  \n",
        "101480                 0.0  \n",
        "101481                 0.0  \n",
        "101482                 2.0  \n",
        "101483                 3.0  \n",
        "101484                 0.0  \n",
        "101485                 1.0  \n",
        "101486                 0.0  \n",
        "101487                 1.0  \n",
        "101488                 0.0  \n",
        "101489                 0.0  \n",
        "101490                 1.0  \n",
        "101491                 2.0  \n",
        "101492                 0.0  \n",
        "101493                 3.0  \n",
        "101494                 2.0  \n",
        "101495                 0.0  \n",
        "101496                 2.0  \n",
        "101497                 0.0  \n",
        "101498                 0.0  \n",
        "101499                 0.0  \n",
        "101500                 4.0  \n",
        "101501                 NaN  \n",
        "101502                 3.0  \n",
        "101503                 0.0  \n",
        "\n",
        "[101503 rows x 11 columns]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "features_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "['RevolvingUtilizationOfUnsecuredLines',\n",
        " 'age',\n",
        " 'NumberOfTime30-59DaysPastDueNotWorse',\n",
        " 'DebtRatio',\n",
        " 'MonthlyIncome',\n",
        " 'NumberOfOpenCreditLinesAndLoans',\n",
        " 'NumberOfTimes90DaysLate',\n",
        " 'NumberRealEstateLoansOrLines',\n",
        " 'NumberOfTime60-89DaysPastDueNotWorse',\n",
        " 'NumberOfDependents']"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mais au fait, quel est la classe de cet objet ? ...\n",
      "Facile, en python, comme en R, on peut utiliser le REPL pour r\u00e9pondre \u00e0 ce genre de question"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "SeriousDlqin2yrs                          int64\n",
        "RevolvingUtilizationOfUnsecuredLines    float64\n",
        "age                                       int64\n",
        "NumberOfTime30-59DaysPastDueNotWorse      int64\n",
        "DebtRatio                               float64\n",
        "MonthlyIncome                           float64\n",
        "NumberOfOpenCreditLinesAndLoans           int64\n",
        "NumberOfTimes90DaysLate                   int64\n",
        "NumberRealEstateLoansOrLines              int64\n",
        "NumberOfTime60-89DaysPastDueNotWorse      int64\n",
        "NumberOfDependents                      float64\n",
        "dtype: object"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Pr\u00e9paration des folds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On pourrait utiliser [`sklearn.cross_validation`](http://scikit-learn.org/stable/modules/cross_validation.html#k-fold) pour pr\u00e9parer les folds mais on le fait \"\u00e0 la main\" pour cette premi\u00e8re fois."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "def kfolds(k,N,seed=None):\n",
      "    random.seed(seed)\n",
      "    out = [ list() for _ in range(k) ]\n",
      "    for n in range(N): \n",
      "        out[random.randrange(k)].append(n)\n",
      "    return(out)\n",
      "\n",
      "K = kfolds(seed=3894,k=5,N=len(train))\n",
      "fold1 = sum(K[1:5],[]) # K[1] + K[2] + K[3] + K[4]\n",
      "\n",
      "xtrain = train.iloc[fold1][train.keys()[1:]]\n",
      "ytrain = train.iloc[fold1][train.keys()[0]]\n",
      "#xtestfinal = test.iloc[:][test.keys()[1:]]\n",
      "#ytestfinal = test.iloc[:][test.keys()[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On n'affiche pas K dans la mesure o\u00f9 N est relativement grand pour \u00eatre affich\u00e9 (15 000)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "source": [
      "3. Imputation des donn\u00e9es manquantes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Le code suivant remplace tous les NaN par la m\u00e9diane de la colonne correspondante. C'est une strat\u00e9gie un peu diff\u00e9rente du code `gbm` en R."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import Imputer\n",
      "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
      "t = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
      "train = imp.fit_transform(train)\n",
      "test = t.fit_transform(test)\n",
      "\n",
      "xtrain = train[fold1,1:]\n",
      "ytrain = train[fold1,0]\n",
      "xtest = train[K[0],1:]\n",
      "ytest = train[K[0],0]\n",
      "xtestfinal = test[:,0:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4. Fonction de renvoie de resultat"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Enregistre dans un fichier csv les resultats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def renvoie(Zfinal):\n",
      "    l = [int(i) for i in range(1,len(Zfinal)+1)]\n",
      "    a = [ [l[i],Zfinal[i]] for i in range (0,len(Zfinal))]\n",
      "    Zfinal2 = [Zfinal,l]\n",
      "    df = pd.DataFrame(data=a)\n",
      "    np.savetxt('preds.csv', df, delimiter =',')\n",
      "    print(\"fichier enregistr\u00e9\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5. GLM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "lr = LogisticRegression(penalty='l2',solver='liblinear',max_iter = 200, tol = 0.00001)\n",
      "lr.fit(xtrain,ytrain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=200, multi_class='ovr', n_jobs=1,\n",
        "          penalty='l2', random_state=None, solver='liblinear', tol=1e-05,\n",
        "          verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On calcule le score sur le fold restant"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score, log_loss\n",
      "lr_preds = lr.predict_proba(xtest)[:,1]\n",
      "print(lr_preds)\n",
      "print(len(lr_preds))\n",
      "print(\"auc:      {}\".format(roc_auc_score(ytest, lr_preds)))\n",
      "a = 0.0\n",
      "limite = 0.5\n",
      "#print(len(xtest))\n",
      "for i in range (0,len(xtest)):\n",
      "    if(((ytest[i]==1) & (lr_preds[i]>limite)) |((ytest[i]==0) & (lr_preds[i]<limite))):\n",
      "        a = a + 1.0\n",
      "a = a/float(len(xtest))\n",
      "print(a)\n",
      "print(\"log_loss: {}\".format(log_loss(ytest,lr_preds)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'lr' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-29-205f6b851fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auc:      {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "On peut vouloir stocker les pr\u00e9dictions sur disque sous forme de fichier csv"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.savetxt('preds.csv', lr_preds, delimiter =',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'lr_preds' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-30-b4c790abae06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preds.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'lr_preds' is not defined"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5. K plus proches voisins"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Premiere approche : comprehension et reduction de dimension pour obtenir un graphe\n",
      "On ne cherchera pas dans un premier temps \u00e0 faire un programme efficace, mais simple a s'assurer qu'il se met en oeuvre correctement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.colors import ListedColormap\n",
      "from sklearn import neighbors, datasets\n",
      "\n",
      "n_neighbors = 1 # On regarde uniquement le voisin le plus proche\n",
      "\n",
      "X= xtrain[:,1:5:3] #Ici on prend que deux colonnes pour pouvoir le repr\u00e9senter. L'age et les revenus ici.\n",
      "y = ytrain\n",
      "\n",
      "nbreapprentissage = 100 # On prend des valeurs faibles pour ne pas surcharger le graphique\n",
      "\n",
      "X = X[0:nbreapprentissage]\n",
      "y = y[0:nbreapprentissage]\n",
      "\n",
      "nbretest = 10 # On fait de m\u00eame pour la base de test\n",
      "\n",
      "x_test = xtest[:,1:5:3]\n",
      "x_test = x_test[0:nbretest-1]\n",
      "y_test = ytest[0:nbretest-1]\n",
      "\n",
      "\n",
      "\n",
      "# On va tester les deux methodes. Uniform regarde la classe la plus presente parmis les n_neighbors plus proches voisins.\n",
      "# Distance va regarder aussi les distances des plus proches voisins et ponderer l importance en fonction de leurs eloigement au point teste.\n",
      "for weights in ['uniform', 'distance']:\n",
      "\n",
      "    # Comment qui fait la classification\n",
      "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
      "    clf.fit(X, y)\n",
      "\n",
      "    # Predit en fonction de la base de donne les valeurs des tests\n",
      "    Z = clf.predict(x_test)\n",
      "    \n",
      "    # Le reste du code n'est pas tres interessant et sert juste a afficher le graphes correctement avec les couleurs\n",
      "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
      "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
      "    plt.figure()\n",
      "    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
      "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
      "    plt.xlim(x_min, x_max)\n",
      "    plt.ylim(y_min, y_max)\n",
      "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
      "              % (n_neighbors, weights))\n",
      "    for i in range(0,nbretest-1):\n",
      "        if(Z[i] == 0):\n",
      "            plt.plot(x_test[i][0], x_test[i][1], 'bs',color ='#FFAAAA')\n",
      "        else:\n",
      "            plt.plot(x_test[i][0], x_test[i][1], 'bs',color ='#AAAAFF')\n",
      "\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Automatically created module for IPython interactive environment\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGBOl/g8T8sXyq+PtnQAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ffb2bc64150>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQf0PXQgdDhSMh+UAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ffb2bb51e90>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En ordonn\u00e9e on a le revenu et en abscisse l'age. Heureusement qu'on n'utilise pas que ces deux informations... car \u00e0 l 'oeil, il nous semble pas possible de bien classer.\n",
      "Les ronds sont les exemples d'entrainements et les carr\u00e9s le test. Evidemment rouge correspond au label 0 et les bleu correspond au label 1\n",
      "\n",
      "On arrete de ce limiter a la dimension deux, et on utilise des fonctions pour calculer l erreur. Il faudra en plus d\u00e9terminer le bon K pour obtenir de meilleurs r\u00e9sultats."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La code qui suit va servir \u00e0 calculer la meilleur valeur de k. Pour des raisons de temps d'execution, je n'ai laiss\u00e9 ici que les valeurs proches de la valeur optimal. On trouve finalement k=182"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(__doc__)\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import neighbors, datasets\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "\n",
      "def kPlusProcheVoisin(n_neighbors):\n",
      "    resultat = [0,0]\n",
      "    # On va tester les deux methodes. Uniform regarde la classe la plus presente parmis les n_neighbors plus proches voisins.\n",
      "    # Distance va regarder aussi les distances des plus proches voisins et ponderer l importance en fonction de leurs eloigement au point teste.\n",
      "    for weights in ['uniform', 'distance']:\n",
      "        # Comment qui fait la classification\n",
      "        #clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
      "        clf = neighbors.KNeighborsClassifier(n_neighbors,weights=weights)\n",
      "\n",
      "        clf.fit(xtrain, ytrain)\n",
      "        # Predit en fonction de la base de donne les valeurs des tests\n",
      "        # Z = clf.predict(xtest)\n",
      "        Z = clf.predict_proba(xtest)\n",
      "        Z = [round(i[1], 5) for i in Z ]\n",
      "        if(weights == 'uniform'):\n",
      "            resultat[0] = format(roc_auc_score(ytest, Z))\n",
      "        else:\n",
      "            resultat[1] = format(roc_auc_score(ytest, Z)) \n",
      "    return(resultat)\n",
      "\n",
      "meilleurk = 0\n",
      "meilleurAUC = 0\n",
      "for i in [181,182,183]:\n",
      "    \n",
      "    resultat = kPlusProcheVoisin(i)\n",
      "    if(resultat[0] > meilleurAUC):\n",
      "        meilleurAUC = resultat[0]\n",
      "        meilleurk=i\n",
      "    if(resultat[1] > meilleurAUC):\n",
      "        meilleurAUC = resultat[1]\n",
      "        meilleurk=i\n",
      "    print(i)\n",
      "    print(resultat)\n",
      "   \n",
      "print(meilleurk)\n",
      "print(meilleurAUC)\n",
      "#print(\"nombre de personne qui ne vont reelement pas rembourser : \" + str(sum(Z)))\n",
      "\n",
      "#print(\"auc:      {}\".format(roc_auc_score(ytest, Z)))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Automatically created module for IPython interactive environment\n",
        "181"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['0.643809243166', '0.656339349318']\n",
        "182"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['0.6441492173', '0.656527750295']\n",
        "183"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['0.643765033963', '0.656351713132']\n",
        "182\n",
        "0.656527750295\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On peut faire des remarques int\u00e9ressante. La m\u00e9thode des K plus proche voisin n'est pas tr\u00e8s optimiser pour cette \u00e9tude, car on veut un r\u00e9sultat qui correspond a une probabilit\u00e9 d'appartenance \u00e0 une classe. Or le syst\u00e8me des K plus proches voisins ne peut que classer de mani\u00e8re discr\u00e8te. Par exemple pour K = 5, on aura que 0;0,2:0,4;0,6;0,8;1 comme valeur possible. Ceci ne permet pas d'obtenir de tr\u00e8s bon r\u00e9sultat au vu de la m\u00e9thode de test qui est l'AUC. En revanche quand K devient assez grand, ici autour de 200, ce probl\u00e8me commence \u00e0 \u00eatre n\u00e9gligeable."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_neighbors = 182\n",
      "clf = neighbors.KNeighborsClassifier(n_neighbors,weights='distance')\n",
      "clf.fit(xtrain, ytrain)\n",
      "Z = clf.predict_proba(xtest)\n",
      "#print(Z)\n",
      "Z = [round(i[1], 5) for i in Z ]\n",
      "#print(Z)\n",
      "#print(type(ytest))\n",
      "#print(type(Z))\n",
      "print(\"auc:      {}\".format(roc_auc_score(ytest, Z)))\n",
      "Zfinal = clf.predict_proba(xtestfinal)\n",
      "Zfinal = [round(i[1], 5) for i in Zfinal ]\n",
      "#print(Zfinal)\n",
      "#renvoie(Zfinal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auc:      0.656527750295\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conclusion : Pas vraiment efficace les K plus proche voisins."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "6. Arbres"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va commencer avec un arbre classique.\n",
      "\n",
      "Le \"if(True)\" permet juste de dire si on veut tester le programme sur Kagel. On effectue le test sur la base donn\u00e9e sans r\u00e9sultat tout en ayant appris avec les param\u00e8tres pr\u00e9c\u00e9demment utilis\u00e9s et toute la base de donn\u00e9e (plus de validation crois\u00e9)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "def Arbre(min_samples_leaf,max_depth,min_samples_split,max_features,criterion,splitter,class_weight,min_impurity_split ):\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        clf = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, max_depth=max_depth, criterion = criterion,\n",
      "                                     splitter=splitter, max_features=max_features, min_samples_split=min_samples_split,\n",
      "                                     class_weight=class_weight, min_impurity_split=min_impurity_split )\n",
      "        clf.fit(xtraink, ytraink)\n",
      "        Z = clf.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(True):\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    return(sum(resultat)/len(resultat))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Arbre(10,10,2,10,\"gini\",\"best\",None,1e-07))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fichier enregistr\u00e9\n",
        "0.833118557938\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ce petit arbre donne d\u00e9j\u00e0 des r\u00e9sultats fou ! 0.810172 en testant sur Kaggle ! On va maintenant essayer de l'optimiser encore un peu. Notamment en uilisant des param\u00e8tres ad\u00e9quats et non plus simplement 10 et 3. (J'ai rechanger les valeurs depuis...)\n",
      "On peut de plus jouer sur le crit\u00e8re \u00e0 minimiser, soit le crit\u00e8re de gini, soit l'entropie.\n",
      "On va garder \"best\" pour le splitter, je ne vois pas trop l'interet du \"random\" ici... M\u00eame si on est pas sur d'atteindre l'optimal avec \"best\", il semble tr\u00e8s logique que cela donne de meilleur r\u00e9sultat que de choisir al\u00e9atoirement la s\u00e9paration !\n",
      "Je ne vois pas pourquoi on metterait max_features a autres choses qu'a 10. Peut \u00eatre pour des questions de rapidit\u00e9 d'ex\u00e9cution, mais cela n'est pas notre probl\u00e8me ici. Apr\u00e8s r\u00e9flexion, ceci peut \u00eatre utiliser lorsqu'on effectue des foret al\u00e9atoire, on ne prend pas toujours toutes les features.\n",
      "J'aime beaucoup le principe de class_weight, en mettant balanced, mais ca marche pas beaucoup\n",
      "\n",
      "Bon, du coup, on va prendre un param\u00e8tre par un param\u00e8tre et regarder la meilleur valeur (des boucles crois\u00e9 prendrais trop de temps sur mon ordinateur) on va donc juste esp\u00e9rer avoir des param\u00e8ters correct au final."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Arbre(10,7,3,10,\"entropy\",\"best\",None,1e-09))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fichier enregistr\u00e9\n",
        "0.849784464147\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [0.1,1e-02,1e-03,1e-04,1e-05,1e-06,1e-07,1e-08,1e-09,1e-10,1e-11,1e-12]\n",
      "for i in list:\n",
      "    a = Arbre(10,7,3,10,\"entropy\",\"best\",None,i)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fichier enregistr\u00e9\n",
        "(0.8447579832841999, 0.1, 0.8447579832841999, 0.1)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.8498085392615999, 0.01)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.8495922746952, 0.001)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.8497930219096, 0.0001)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.849707402486, 1e-05)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.8497753419834, 1e-06)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.8497788954864001, 1e-07)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.8497978889881999, 1e-08)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498085392615999, 0.01, 0.8498008120269999, 1e-09)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498099998838, 1e-10, 0.8498099998838, 1e-10)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498099998838, 1e-10, 0.8496935368254, 1e-11)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8498099998838, 1e-10, 0.8496815487617999, 1e-12)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "10^-8 a obtenu les meilleurs valeur, on va donc mettre 10^-8."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "for i in range(1,10):\n",
      "    a = Arbre(10,i,3,10,\"entropy\",\"best\",None,1e-08)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fichier enregistr\u00e9\n",
        "(0.655748804039, 1, 0.655748804039, 1)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.7829714049422, 2, 0.7829714049422, 2)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8192314368806001, 3, 0.8192314368806001, 3)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8315896709414, 4, 0.8315896709414, 4)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.846227662211, 5, 0.846227662211, 5)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8488213842892002, 6, 0.8488213842892002, 6)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8497072912347999, 7, 0.8497072912347999, 7)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8497072912347999, 7, 0.8461422403872, 8)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8497072912347999, 7, 0.8389196993672, 9)\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va garder 7 comme meilleur valeur pour la profondeur."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "for i in range(1,3):\n",
      "    a = Arbre(i,7,3,10,\"entropy\",\"best\",None,1e-08)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fichier enregistr\u00e9\n",
        "(0.8468858791528, 1, 0.8468858791528, 1)\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8468858791528, 1, 0.8466042141614001, 2)\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La meilleur valeur semble etre 70, m\u00eame si cela ne change pas beaucoup si on met une valeur sup\u00e9rieur. Il faut donc au moins 70 \u00e9l\u00e9ments pour constituer une feuille."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [2,100,200,300,400,500,600,700,800,900,1000]\n",
      "for i in list:\n",
      "    print(i)\n",
      "    a = Arbre(70,7,i,10,\"entropy\",\"best\",None,1e-08)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8533500006603999, 2, 0.8533500006603999, 2)\n",
        "100\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8533500006603999, 2, 0.8533500006603999, 100)\n",
        "200\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8533791572845999, 200, 0.8533791572845999, 200)\n",
        "300\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.853531732178, 300, 0.853531732178, 300)\n",
        "400\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8536708526758, 400, 0.8536708526758, 400)\n",
        "500\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8537577556934, 500, 0.8537577556934, 500)\n",
        "600\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8537577556934, 500, 0.8537326536769999, 600)\n",
        "700\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8537577556934, 500, 0.8537275337700001, 700)\n",
        "800\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8537577556934, 500, 0.853702190494, 800)\n",
        "900\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8537577556934, 500, 0.8537575852931999, 900)\n",
        "1000\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.8537631223890001, 1000, 0.8537631223890001, 1000)\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1000 semble \u00eatre la meilleur valeur, mais cela ne change pas grand chose."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Arbre(70,7,1000,10,\"entropy\",\"best\",None,1e-08))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fichier enregistr\u00e9\n",
        "0.853763122389\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "0.851371 Sur Kaggle ! Pas mal du tout, les for\u00eats promettent !"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Random Forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "def foret(n_estimators,min_samples_leaf,max_depth,min_samples_split,max_features,criterion,class_weight,min_impurity_split):\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        clf = RandomForestClassifier(n_estimators=n_estimators,min_samples_leaf=min_samples_leaf, max_depth=max_depth,criterion = criterion,max_features=max_features,min_samples_split=min_samples_split,class_weight=class_weight,min_impurity_split=min_impurity_split)\n",
      "        clf.fit(xtraink, ytraink)\n",
      "        Z = clf.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    return(sum(resultat)/len(resultat))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(foret(10,70,7,1000,10,\"entropy\",None,1e-08))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.859001252781\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va appliquer la meme methode pour trouver les param\u00e8tres optimals, sachant qu'on est d\u00e9j\u00e0 parti avec les param\u00e8tres optimal des arbres. La d\u00e9j\u00e0 le temps de calcul est super long... mais il faut dire que je n'ais pas un PC efficace. La d\u00e9tection des param\u00e8tres optimaux est donc l\u00e9g\u00e8rement bacl\u00e9."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [10]\n",
      "for i in list:\n",
      "    print(i)\n",
      "    a = foret(i,70,7,1000,10,\"entropy\",None,1e-08)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10\n",
        "(0.858910362042, 10, 0.858910362042, 10)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Beaucoup trop long quand on augmente i... et la valeur change pas des masses, on va rester sur 10 pour les autres tests, mais si une plus grande valeur parait mieux (300 notamment)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [2,3,4,5,70,100]\n",
      "for i in list:\n",
      "    print(i)\n",
      "    a = foret(10,i,7,1000,10,\"entropy\",None,1e-08)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va garder 70"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(foret(300,70,7,1000,10,\"entropy\",None,1e-08))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.859852266333\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "J'ai ici r\u00e9\u00e9crit le code, avec la m\u00e9thode qui permet de d\u00e9terminer directement la valeur optimal. Assez pratique, mais pas tellement plus efficace que mes m\u00e9thodes pr\u00e9c\u00e9dents avec un ordinateur aussi peu puissant.\n",
      "La premi\u00e8re raison est qu'on a pas en temps r\u00e9el des informations, on est obliger d'attendre la fin, alors que avec les boucles, d\u00e8s que la valeur de changeait plus beaucoup j'arretais le programme.\n",
      "De plus, la m\u00e9thode qui semble la plus efficace (logiquement) semble \u00eatre RandomizedSearchCV, mais elle a besoin de beaucoup de temps pour converger car elle est extr\u00e8mement efficace quand on essaye de faire de l'optimisation des param\u00e8tres de mani\u00e8re crois\u00e9 (plusieurs en m\u00eame temps).\n",
      "\n",
      "Ceci n'est pas encore parfait car j'ai compris plus tard que on pouvait indiquer qu'on voulait faire une validation crois\u00e9e... Le programme \"propre\" est celui d'Adaboost"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from scipy.stats import randint as sp_randint\n",
      "from sklearn.model_selection import RandomizedSearchCV\n",
      "def foret2():\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        print(k)\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        \n",
      "        clf = RandomForestClassifier()\n",
      "        n_iter_search = 10\n",
      "        param_dist = {\"max_depth\": [3, None],\n",
      "              \"max_features\": sp_randint(1, 11),\n",
      "              \"min_samples_split\": sp_randint(2, 11),\n",
      "              \"min_samples_leaf\": sp_randint(1, 11),\n",
      "              \"bootstrap\": [True, False],\n",
      "              \"criterion\": [\"gini\", \"entropy\"]}\n",
      "        random_search = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=n_iter_search,)\n",
      "        \n",
      "        random_search.fit(xtraink, ytraink)\n",
      "        \n",
      "        \n",
      "        Z = random_search.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "        if(resultat[k]>=max(resultat)):\n",
      "            paraOpti=random_search.best_estimator_\n",
      "            print(\"le meilleur k actuellement est :\")\n",
      "            print(k)\n",
      "            print(\" et les paras sont :\")\n",
      "            print(paraOpti)\n",
      "            print(\"et la valeur de l AUC :\")\n",
      "            print(resultat[k])\n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    print(paraOpti)\n",
      "    return(sum(resultat)/len(resultat))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(foret2())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "le meilleur k actuellement est :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0\n",
        " et les paras sont :\n",
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=3, max_features=6, max_leaf_nodes=None,\n",
        "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
        "            min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
        "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
        "            verbose=0, warm_start=False)\n",
        "et la valeur de l AUC :\n",
        "0.849149577846\n",
        "1\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=3, max_features=6, max_leaf_nodes=None,\n",
        "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
        "            min_samples_split=7, min_weight_fraction_leaf=0.0,\n",
        "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
        "            verbose=0, warm_start=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.843422420502\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Et puis comme c'est trop long de tout tester, on va passer a l'Adaboost, on a quand m\u00eame des tr\u00e8s bon r\u00e9sultats. Kaggel: 0.850392\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "ADABOOST"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Adaboost sans la recherche automatique d'optimal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "def adaboost(algorithm,n_estimators,learning_rate,base_estimator,random_state):\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        print(k)\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        clf = AdaBoostClassifier(algorithm=algorithm,\n",
      "                                 n_estimators=n_estimators,\n",
      "                                 learning_rate=learning_rate,base_estimator=base_estimator,\n",
      "                                 random_state=random_state)\n",
      "        clf.fit(xtraink, ytraink)\n",
      "        Z = clf.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    return(sum(resultat)/len(resultat))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(adaboost(algorithm='SAMME.R',\n",
      "          base_estimator=None,\n",
      "          learning_rate=1, n_estimators=70, random_state=None))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.860153307472"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La, c'est fou le progr\u00e8s !! On a passer par barre des 0.86 ! Et on a m\u00eame pas optimiser les param\u00e8tres ! M\u00eame si il semble que les param\u00e8tres a optimiser soit pas hyper nombreux, on va commencer par le nombre d estimateur\n",
      "\n",
      "Par contre les programmes suivants ne sont plus \u00e0 jour, mais ils servent de toutes fa\u00e7on juste a calculer les param\u00e8tres optimaux."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [i*10 for i in range(7,8)]\n",
      "#print(list)\n",
      "for i in list:\n",
      "    a = adaboost(i,1)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.860153307472, 70, 0.860153307472, 70)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On va prendre 70"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [i*0.1 for i in range(1,1)]\n",
      "#print(list)\n",
      "for i in list:\n",
      "    a = adaboost(70,i)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1 est la meilleur valeur"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [i for i in range(1,1)]\n",
      "#print(list)\n",
      "for i in list:\n",
      "    a = adaboost(70,1,algorithm=DecisionTreeClassifier(max_depth=i, min_samples_leaf=1))\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(adaboost(learning_rate=1, n_estimators=70, random_state=None, algorithm=\"SAMME.R\",\n",
      "               base_estimator=DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.860153307472"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La on optimise automatiquement le programme."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from scipy.stats import randint as sp_randint\n",
      "from sklearn.model_selection import RandomizedSearchCV\n",
      "\n",
      "def adaboost2():\n",
      "    clf = AdaBoostClassifier()\n",
      "    \n",
      "    n_iter_search = 1 #A Augmenter si on veux que cela soit utile...\n",
      "    \n",
      "    criterion='gini'\n",
      "    splitter='best'\n",
      "    max_depth=None\n",
      "    min_samples_split=2\n",
      "    min_samples_leaf=1\n",
      "    min_weight_fraction_leaf=0.0\n",
      "    max_features=None\n",
      "    random_state=None\n",
      "    max_leaf_nodes=None\n",
      "    min_impurity_split=1e-07\n",
      "    class_weight=None\n",
      "    presort=False\n",
      "    listeArbre = []\n",
      "    for i in range(1,10):\n",
      "        listeArbre.append(DecisionTreeClassifier(min_samples_leaf=min_samples_leaf,\n",
      "                                max_depth=i,\n",
      "                                criterion = criterion,\n",
      "                                splitter=splitter,\n",
      "                                max_features=max_features,\n",
      "                                min_samples_split=min_samples_split,\n",
      "                                class_weight=class_weight,\n",
      "                                min_impurity_split=min_impurity_split ))\n",
      "    \n",
      "    param_dist = {\"algorithm\": [\"SAMME.R\",\"SAMME\"],\n",
      "            \"n_estimators\": sp_randint(1, 500),\n",
      "            \"learning_rate\": [i*0.01 for i in range(1,101)],\n",
      "            \"base_estimator\": listeArbre,}\n",
      "    print(\"On choisit les param\u00e8tres al\u00e9atoirement\")\n",
      "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=n_iter_search,n_jobs=-1,cv=5)\n",
      "    print(\"On commence l'apprentissage\")\n",
      "    random_search.fit(xtrain, ytrain)\n",
      "    print(\"On a finil'apprentissage\")\n",
      "    Z = random_search.predict_proba(xtest)\n",
      "    Z = [i[1] for i in Z ]\n",
      "\n",
      "    resultat = float(format(roc_auc_score(ytest, Z)))\n",
      "    estimator=random_search.best_estimator_\n",
      "    print(\"Le meilleur estimateur :\")\n",
      "    print(estimator)\n",
      "    print(\"et la valeur de l AUC :\")\n",
      "    print(resultat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adaboost2()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "On choisit les param\u00e8tres al\u00e9atoirement\n",
        "On commence l'apprentissage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "On a finil'apprentissage\n",
        "Le meilleur estimateur :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AdaBoostClassifier(algorithm='SAMME.R',\n",
        "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
        "            max_features=None, max_leaf_nodes=None,\n",
        "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
        "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "            presort=False, random_state=None, splitter='best'),\n",
        "          learning_rate=0.46, n_estimators=202, random_state=None)\n",
        "et la valeur de l AUC :\n",
        "0.689963765676\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      ".855210.\n",
      "\n",
      "Voici juste un exemple, normal que la valeur soit ridicul car on a fait un seul test... "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "GadientBoosting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "def gradientBoosting(loss, learning_rate, n_estimators, subsample, criterion,\n",
      "                                   min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_depth,\n",
      "                                   min_impurity_split, init, random_state, max_features, verbose,\n",
      "                                   max_leaf_nodes, warm_start, presort):\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        print(k)\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        clf=GradientBoostingClassifier(loss=loss, learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample,\n",
      "                                   criterion=criterion,\n",
      "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
      "                                   min_weight_fraction_leaf=min_weight_fraction_leaf, max_depth=max_depth,\n",
      "                                   min_impurity_split=min_impurity_split, init=init, random_state=random_state,\n",
      "                                   max_features=max_features, verbose=verbose,\n",
      "                                   max_leaf_nodes=max_leaf_nodes, warm_start=warm_start, presort=presort)        \n",
      "        clf.fit(xtraink, ytraink)\n",
      "        Z = clf.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    return(sum(resultat)/len(resultat))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(gradientBoosting(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse',\n",
      "                                   min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3,\n",
      "                                   min_impurity_split=1e-07, init=None, random_state=None, max_features=None, verbose=0,\n",
      "                                   max_leaf_nodes=None, warm_start=False, presort='auto'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.864206004946"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La c'est fou, 0.864 au premier coup avec des param\u00e8tres au pif !\n",
      "\n",
      "On essaye ici le m\u00e9thode Grid pour optimiser les param\u00e8tres, on balaye maintenant toutes les possibilit\u00e9es."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from scipy.stats import randint as sp_randint\n",
      "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "def gradientBoosting2():\n",
      "    \n",
      "    loss='deviance'\n",
      "    learning_rate=0.1\n",
      "    n_estimators=100\n",
      "    subsample=1.0\n",
      "    criterion='friedman_mse'\n",
      "    min_samples_split=2\n",
      "    min_samples_leaf=1\n",
      "    min_weight_fraction_leaf=0.0\n",
      "    max_depth=3\n",
      "    min_impurity_split=1e-07\n",
      "    init=None\n",
      "    random_state=None\n",
      "    max_features=None\n",
      "    verbose=0\n",
      "    max_leaf_nodes=None\n",
      "    warm_start=False\n",
      "    presort='auto'\n",
      "            \n",
      "    clf = GradientBoostingClassifier(loss=loss, learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample,\n",
      "                                   criterion=criterion,\n",
      "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
      "                                   min_weight_fraction_leaf=min_weight_fraction_leaf, max_depth=max_depth,\n",
      "                                   min_impurity_split=min_impurity_split, init=init, random_state=random_state,\n",
      "                                   max_features=max_features, verbose=verbose,\n",
      "                                   max_leaf_nodes=max_leaf_nodes, warm_start=warm_start, presort=presort)\n",
      "    \n",
      "    n_iter_search = 1\n",
      "    \n",
      "    param_grid = {\"loss\": [\"deviance\"],\n",
      "            \"n_estimators\": [i*10 for i in range(1,20)]\n",
      "            #\"learning_rate\": [i*0.01 for i in range(1,101)],\n",
      "            #\"criterion\": [\"friedman_mse\"]\n",
      "            }\n",
      "    \n",
      "    param_dist = {\"loss\": [\"SAMME.R\",\"SAMME\"],\n",
      "            \"n_estimators\": sp_randint(1, 2),\n",
      "            \"learning_rate\": [i*0.1 for i in range(1,11)],\n",
      "            \"criterion\": [\"friedman_mse\"],}\n",
      "    \n",
      "    #print(\"On choisit les parametres aleatoirement\")\n",
      "    #random_search = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=n_iter_search,n_jobs=-1,cv=5)\n",
      "    random_search = GridSearchCV(clf,param_grid=param_grid,n_jobs=-1,cv=5)\n",
      "    print(\"On commence l apprentissage\")\n",
      "    random_search.fit(xtrain, ytrain)\n",
      "    print(\"on a fini l'apprentissage\")\n",
      "    Z = random_search.predict_proba(xtest)\n",
      "    Z = [i[1] for i in Z ]\n",
      "\n",
      "    resultat = float(format(roc_auc_score(ytest, Z)))\n",
      "    paraOpti=random_search.best_estimator_\n",
      "    print(\"Les paras sont :\")\n",
      "    print(paraOpti)\n",
      "    print(\"et la valeur de l AUC :\")\n",
      "    print(resultat)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradientBoosting2()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "On choisit les parametres aleatoirement\n",
        "On commence l apprentissage\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "on a fini l'apprentissage\n",
        "Les paras sont :\n",
        "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
        "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "              max_features=None, max_leaf_nodes=None,\n",
        "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
        "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "              n_estimators=50, presort='auto', random_state=None,\n",
        "              subsample=1.0, verbose=0, warm_start=False)\n",
        "et la valeur de l AUC :\n",
        "0.870219318598\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Valeur optimal :\n",
      " Les paras sont :\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=50, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "et la valeur de l AUC :\n",
      "0.870219318598\n",
      "\n",
      "Ici, je ne pr\u00e9tend pas avoir essayer toutes les possibilit\u00e9s (param\u00e8tres pas forc\u00e9ment totallement optimiser), mais on a d\u00e9j\u00e0 le meilleur r\u00e9sultat pour le moment. Enfaite cela est a relativiser, car avec la d\u00e9tection automatique de valeur, le programme prend la meilleur AUC avec la crosse validation, or jusqua la je prennais la moyenne sur les 5 tests, il y a qu'a regarder le programme qui suis... Il me parrait d'ailleur tr\u00e8s \u00e9trange qu'on prenne la plus grande valeur et pas la moyenne ! Selon mes crit\u00e8res ces param\u00e8tres sont pas tr\u00e8s efficaces."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradientBoosting(criterion='friedman_mse', init=None, learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                 max_features=None, max_leaf_nodes=None, min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "                 min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=50, presort='auto',\n",
      "                 random_state=None, subsample=1.0, verbose=0, warm_start=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "On attacque le vrai project"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "0.8618161926017999"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [i for i in range(2,10)]\n",
      "#print(list)\n",
      "for i in list:\n",
      "    a = gradientBoosting(loss='deviance', learning_rate=0.2, n_estimators=110, subsample=1.0, criterion='friedman_mse',\n",
      "                                   min_samples_split=6, min_samples_leaf=5, min_weight_fraction_leaf=0.005, max_depth=4,\n",
      "                                   min_impurity_split=10**(-7), init=None, random_state=None, max_features=None, verbose=0,\n",
      "                                   max_leaf_nodes=i, warm_start=False, presort='auto')\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gradientBoosting(loss='deviance', learning_rate=0.2, n_estimators=110, subsample=1.0, criterion='friedman_mse',\n",
      "                                   min_samples_split=6, min_samples_leaf=5, min_weight_fraction_leaf=0.005, max_depth=4,\n",
      "                                   min_impurity_split=10**(-7), init=None, random_state=None, max_features=None, verbose=0,\n",
      "                                   max_leaf_nodes=None, warm_start=False, presort='auto')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "On attacque le vrai project"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 89,
       "text": [
        "0.8657164840648"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pas une am\u00e9lioration \u00e9norme en optimisant les param\u00e8tres..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "On va faire voter Adaboost et Gradientboosting !"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pas grand chose \u00e0 dire, on fait voter les deux, on fait une sorte de moyenne qu'on peut \u00e9videmment pond\u00e9r\u00e9."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from scipy.stats import randint as sp_randint\n",
      "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
      "from sklearn.ensemble import GradientBoostingClassifier,VotingClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "def vote():\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        print(k)\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        clf1=GradientBoostingClassifier(loss='deviance', learning_rate=0.2, n_estimators=110, subsample=1.0, criterion='friedman_mse',\n",
      "                                   min_samples_split=6, min_samples_leaf=5, min_weight_fraction_leaf=0.005, max_depth=4,\n",
      "                                   min_impurity_split=10**(-7), init=None, random_state=None, max_features=None, verbose=0,\n",
      "                                   max_leaf_nodes=None, warm_start=False, presort='auto')    \n",
      "        \n",
      "        clf2 = AdaBoostClassifier(learning_rate=1, n_estimators=70, random_state=None, algorithm=\"SAMME.R\",\n",
      "               base_estimator=DecisionTreeClassifier(max_depth=1, min_samples_leaf=1))\n",
      "        vote = VotingClassifier(estimators=[('Gradient', clf1), ('ADA', clf2)],voting='soft')\n",
      "        vote.fit(xtraink, ytraink)\n",
      "        Z = vote.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        vote.fit(xtrain, ytrain)    \n",
      "        Zfinal = vote.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    print(\"Meilleur resultat :\")\n",
      "    print(max(resultat))\n",
      "    return(sum(resultat)/len(resultat))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(vote())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "On attacque le vrai project"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fichier enregistr\u00e9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Meilleur resultat :\n",
        "0.873397179121\n",
        "0.865873004927\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Meilleur resultat :\n",
      "0.873397179121\n",
      "0.865873004927\n",
      "\n",
      "\n",
      "Private Score :0.867111\n",
      "Public Score : 0.860820\n",
      "avec Kagel, meilleur performance, meilleur m\u00eame que avec juste le GradientBoosting, alors qu'il donne a priori de meilleur r\u00e9sultat !\n",
      "Private Score : 0.866784\n",
      "Public Score : 0.860618"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reseau de neurone"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neural_network import MLPClassifier\n",
      "def reseaudeneurone(hidden_layer_sizes, activation, solver, alpha, batch_size, \n",
      "                             learning_rate, learning_rate_init, power_t, max_iter, shuffle, \n",
      "                             random_state, tol, verbose, warm_start, momentum, nesterovs_momentum, \n",
      "                             early_stopping, validation_fraction, beta_1, beta_2, epsilon):\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        print(k)\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, alpha=alpha, batch_size=batch_size, \n",
      "                             learning_rate=learning_rate, learning_rate_init=learning_rate_init, power_t=power_t, max_iter=max_iter,\n",
      "                             shuffle=shuffle, \n",
      "                             random_state=random_state, tol=tol, verbose=verbose, warm_start=warm_start, momentum=momentum,\n",
      "                             nesterovs_momentum=nesterovs_momentum, \n",
      "                             early_stopping=early_stopping, validation_fraction=validation_fraction, beta_1=beta_1,\n",
      "                             beta_2=beta_2, epsilon=epsilon)\n",
      "        clf.fit(xtraink, ytraink)\n",
      "        Z = clf.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    return(sum(resultat)/len(resultat))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(reseaudeneurone(hidden_layer_sizes=(5,2), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', \n",
      "                             learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
      "                             random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
      "                             early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.520605217295"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pas fou tout ca... Mais on devrait pouvoir bien s'amuser avec tous les param\u00e8tres. J'ai \u00e9crit le programme qui optimise les param\u00e8tres, mais on va pas tr\u00e8s loin avec ce r\u00e9seau de neuronne... C'est tellement al\u00e9atoire... J'arrive pas a cern\u00e9 les bonnes valeurs..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from scipy.stats import randint as sp_randint\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "def reseaudeneurone2():\n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        print(k)\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        for j in list:\n",
      "            fold = sum(K[j:j+1],fold)\n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "        clf = MLPClassifier(hidden_layer_sizes=(5,2), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', \n",
      "                             learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
      "                             random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
      "                             early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
      "        n_iter_search = 4\n",
      "        param_dist = {\"max_depth\": [3, None],\n",
      "              \"max_features\": sp_randint(1, 11),\n",
      "              \"min_samples_split\": sp_randint(1, 11),\n",
      "              \"min_samples_leaf\": sp_randint(1, 11),\n",
      "              \"bootstrap\": [True, False],\n",
      "              \"criterion\": [\"gini\", \"entropy\"]}\n",
      "        random_search = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=n_iter_search)\n",
      "        random_search.fit(xtraink, ytraink)\n",
      "        Z = clf.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    return(sum(resultat)/len(resultat))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [1-i*0.1 for i in range(1,2)]\n",
      "for i in list:\n",
      "    a = reseaudeneurone(hidden_layer_sizes=(3,2), activation='relu', solver='adam', alpha=0.0002, batch_size='auto', \n",
      "                             learning_rate='constant', learning_rate_init=0.002, power_t=0.5, max_iter=10000, shuffle=True, \n",
      "                             random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
      "                             early_stopping=False, validation_fraction=0.1, beta_1=0.8, beta_2=0.999, epsilon=1e-08)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0.5666195466248001, 0.9, 0.5666195466248001, 0.9)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SVM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "J'ai lu sur internet que SVC prennait beaucoup de temps, mais la c'est d\u00e9raisonnable... Avec 20 features, c'est m\u00eame pas instantan\u00e9..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "def SVM(C, kernel, degree, gamma, coef0, shrinking, probability, tol, \n",
      "                 cache_size, class_weight, verbose, max_iter, decision_function_shape, random_state):\n",
      "    \n",
      "    resultat = [0,0,0,0,0]\n",
      "    for k in range(0,5):\n",
      "        print(k)\n",
      "        fold =[]\n",
      "        list = [0,1,2,3,4]\n",
      "        list.remove(k)\n",
      "        #for j in list:\n",
      "            #fold = sum(K[j:j+1],fold)\n",
      "            \n",
      "        fold = K[2]\n",
      "        fold = fold[1:20]\n",
      "            \n",
      "        xtestk = train[K[k],1:]\n",
      "        ytestk = train[K[k],0]\n",
      "        xtraink = train[fold,1:]\n",
      "        ytraink = train[fold,0]\n",
      "\n",
      "        \n",
      "        print(\"on commence la classification\")\n",
      "        clf=SVC(kernel=kernel,probability = probability) \n",
      "       \n",
      "        print(\"on commence l'apprentissage\")\n",
      "\n",
      "        clf.fit(xtraink, ytraink)\n",
      "        #clf=SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, coef0=coef0, shrinking=shrinking, probability=probability, tol=tol, \n",
      "         #        cache_size=cache_size, class_weight=class_weight, verbose=verbose, max_iter=max_iter, \n",
      "          #       decision_function_shape=decision_function_shape, random_state=random_state)\n",
      "        print(\"on fini l'apprentissage\")\n",
      "\n",
      "        Z = clf.predict_proba(xtestk)\n",
      "        Z = [i[1] for i in Z ]\n",
      "\n",
      "        resultat[k] = float(format(roc_auc_score(ytestk, Z)))\n",
      "    \n",
      "    if(False):\n",
      "        print(\"On attacque le vrai project\")\n",
      "        fold = sum(K[0:5],[])\n",
      "        xtrain = train[fold,1:]\n",
      "        ytrain = train[fold,0]\n",
      "        clf.fit(xtrain, ytrain)    \n",
      "        Zfinal = clf.predict_proba(xtestfinal)\n",
      "        Zfinal = [i[1] for i in Zfinal ]\n",
      "        renvoie(Zfinal)\n",
      "    #print(resultat)\n",
      "    return(sum(resultat)/len(resultat))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SVM(C=1.0, kernel='linear', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=True, tol=0.001,\n",
      "                 cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "on commence la classification\n",
        "on commence l'apprentissage\n",
        "on fini l'apprentissage"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1\n",
        "on commence la classification\n",
        "on commence l'apprentissage\n",
        "on fini l'apprentissage"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2\n",
        "on commence la classification\n",
        "on commence l'apprentissage\n",
        "on fini l'apprentissage"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3\n",
        "on commence la classification\n",
        "on commence l'apprentissage\n",
        "on fini l'apprentissage"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4\n",
        "on commence la classification\n",
        "on commence l'apprentissage\n",
        "on fini l'apprentissage"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.45396767610620004"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SVM(C=1.0, kernel='linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best = 0\n",
      "besti = 0\n",
      "list = [i for i in range(1,10)]\n",
      "list = [\"log\", \"modified_huber\"]\n",
      "for i in list:\n",
      "    a = SVM(loss=i, penalty='l2', alpha=0.0001,l1_ratio=0.15, fit_intercept=True, n_iter=5, shuffle=True,verbose=0,\n",
      "            epsilon=0.1, n_jobs=1, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5,class_weight=None, \n",
      "            warm_start=False, average=False)\n",
      "    if (a > best):\n",
      "        best = a\n",
      "        besti = i\n",
      "    print(best,besti,a,i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}